#!/usr/bin/env python3
"""
Final Report Generator - Comprehensive Analysis Report
Combines LMS Design analysis with Activity analysis for final rankings.

Usage:
    python3 scripts/discovery/final_report_generator.py
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    HAS_PLOTTING = True
    plt.style.use('seaborn-v0_8-whitegrid')
except ImportError:
    HAS_PLOTTING = False


class FinalReportGenerator:
    """Generate comprehensive analysis report combining all data sources."""

    def __init__(self):
        self.data_dir = Path('data/discovery')
        self.output_dir = self.data_dir / 'final_report'
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # Load datasets
        self.df_design = pd.read_csv(self.data_dir / 'course_analysis_latest.csv')
        self.df_activity = pd.read_csv(self.data_dir / 'activity_analysis_latest.csv')

        print(f"Loaded LMS Design data: {len(self.df_design)} courses")
        print(f"Loaded Activity data: {len(self.df_activity)} courses")

        # Merge datasets
        self._merge_datasets()

    def _merge_datasets(self):
        """Merge design and activity datasets."""
        # Select key columns from each dataset
        design_cols = [
            'course_id', 'course_name', 'account_id', 'term_name', 'total_students',
            'assignment_count', 'graded_assignment_count', 'quiz_count', 'module_count',
            'file_count', 'discussion_count', 'page_count',
            'grade_availability_score', 'grade_variance_score', 'class_balance_score',
            'design_richness_score', 'activity_score', 'prediction_potential_score'
        ]

        activity_cols = [
            'course_id', 'students_with_grades', 'grade_coverage', 'grade_mean', 'grade_std',
            'failure_rate', 'students_with_activity', 'activity_coverage',
            'avg_page_views', 'avg_participations', 'avg_missing_rate',
            'avg_on_time_rate', 'avg_late_rate',
            'students_active_last_7_days', 'students_active_last_30_days',
            'activity_engagement_score', 'tardiness_score', 'recency_score',
            'activity_prediction_score'
        ]

        # Get available columns
        design_available = [c for c in design_cols if c in self.df_design.columns]
        activity_available = [c for c in activity_cols if c in self.df_activity.columns]

        df_d = self.df_design[design_available].copy()
        df_a = self.df_activity[activity_available].copy()

        # Rename to avoid conflicts
        df_a = df_a.rename(columns={
            'activity_prediction_score': 'activity_based_score',
            'activity_engagement_score': 'engagement_score'
        })

        # Merge on course_id
        self.df = pd.merge(df_d, df_a, on='course_id', how='outer', suffixes=('_design', '_activity'))

        # Calculate combined score
        self._calculate_combined_score()

        print(f"Merged dataset: {len(self.df)} courses")

    def _calculate_combined_score(self):
        """Calculate combined score from both analyses."""
        # Normalize scores to 0-100
        design_score = self.df['prediction_potential_score'].fillna(0)
        activity_score = self.df['activity_based_score'].fillna(0)

        # Combined score: 50% design + 50% activity
        self.df['combined_score'] = (design_score * 0.5) + (activity_score * 0.5)

        # Alternative: weighted by data availability
        has_design = design_score > 0
        has_activity = activity_score > 0

        self.df['combined_score_weighted'] = np.where(
            has_design & has_activity,
            (design_score * 0.5) + (activity_score * 0.5),
            np.where(has_design, design_score * 0.8, activity_score * 0.8)
        )

    def generate_report(self):
        """Generate the complete markdown report."""
        report = []

        # Header
        report.append(self._header())

        # Executive Summary
        report.append(self._executive_summary())

        # Methodology
        report.append(self._methodology())

        # Data Overview
        report.append(self._data_overview())

        # Key Findings
        report.append(self._key_findings())

        # Campus Analysis
        report.append(self._campus_analysis())

        # Engagement Patterns
        report.append(self._engagement_patterns())

        # Risk Analysis
        report.append(self._risk_analysis())

        # Top 50 Courses
        report.append(self._top_50_courses())

        # Conclusions
        report.append(self._conclusions())

        # Technical Appendix
        report.append(self._technical_appendix())

        # Generate visualizations
        if HAS_PLOTTING:
            self._generate_visualizations()

        # Save report
        report_text = '\n'.join(report)
        report_path = self.output_dir / 'informe_completo_analisis.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report_text)

        print(f"\nReport saved to: {report_path}")

        # Save top 50 CSV
        self._save_top_50_csv()

        return report_text

    def _header(self):
        """Generate report header."""
        return f"""# Informe Completo de An√°lisis de Cursos Canvas LMS

## Universidad Aut√≥noma de Chile - Sistema de Alerta Temprana

**Fecha de Generaci√≥n:** {datetime.now().strftime('%d de %B de %Y')}
**Per√≠odo de An√°lisis:** Segundo Semestre 2025
**Fuente de Datos:** Canvas LMS API (Ambiente de Pruebas)

---

## √çndice

1. [Resumen Ejecutivo](#1-resumen-ejecutivo)
2. [Metodolog√≠a](#2-metodolog√≠a)
3. [Panorama de Datos](#3-panorama-de-datos)
4. [Hallazgos Principales](#4-hallazgos-principales)
5. [An√°lisis por Campus](#5-an√°lisis-por-campus)
6. [Patrones de Engagement](#6-patrones-de-engagement)
7. [An√°lisis de Riesgo](#7-an√°lisis-de-riesgo)
8. [Top 50 Cursos para Modelado Predictivo](#8-top-50-cursos-para-modelado-predictivo)
9. [Conclusiones y Recomendaciones](#9-conclusiones-y-recomendaciones)
10. [Ap√©ndice T√©cnico](#10-ap√©ndice-t√©cnico)

---
"""

    def _executive_summary(self):
        """Generate executive summary."""
        total = len(self.df)
        with_grades = len(self.df[self.df['students_with_grades'] >= 15])
        with_activity = len(self.df[self.df['students_with_activity'] >= 15])
        high_potential = len(self.df[self.df['combined_score'] >= 50])

        # Top course
        top_course = self.df.nlargest(1, 'combined_score').iloc[0]

        return f"""## 1. Resumen Ejecutivo

Este informe presenta un an√°lisis exhaustivo de **{total} cursos** del sistema Canvas LMS de la Universidad Aut√≥noma de Chile, combinando dos perspectivas complementarias:

1. **An√°lisis de Dise√±o LMS** - Eval√∫a la estructura y calidad del dise√±o instruccional
2. **An√°lisis de Actividad** - Mide el engagement y comportamiento estudiantil

### M√©tricas Clave

| Indicador | Valor | Interpretaci√≥n |
|-----------|-------|----------------|
| **Cursos Analizados** | {total} | Cobertura completa de PREGRADO |
| **Con Datos de Notas (‚â•15 est.)** | {with_grades} ({with_grades/total*100:.1f}%) | Base para modelado supervisado |
| **Con Datos de Actividad (‚â•15 est.)** | {with_activity} ({with_activity/total*100:.1f}%) | Base para early warning |
| **Alto Potencial (score ‚â•50)** | {high_potential} ({high_potential/total*100:.1f}%) | Candidatos inmediatos |

### Hallazgo Principal

> **El curso con mayor potencial predictivo es "{top_course['course_name']}"** con un score combinado de **{top_course['combined_score']:.1f}/100**, integrando tanto m√©tricas de dise√±o instruccional como patrones de actividad estudiantil.

### Conclusi√≥n Ejecutiva

Del an√°lisis se desprende que existe un **n√∫cleo de {high_potential} cursos** con caracter√≠sticas √≥ptimas para implementar sistemas de alerta temprana. Estos cursos presentan:
- Suficiente varianza en calificaciones para distinguir patrones
- Datos de actividad ricos para predicci√≥n temprana
- Balance adecuado entre estudiantes aprobados y reprobados

---
"""

    def _methodology(self):
        """Generate methodology section."""
        return """## 2. Metodolog√≠a

### 2.1 Fuentes de Datos

El an√°lisis integra datos de **dos pipelines complementarios**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARQUITECTURA DE AN√ÅLISIS DUAL                            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                                             ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ   ‚îÇ  AN√ÅLISIS DE DISE√ëO  ‚îÇ         ‚îÇ AN√ÅLISIS DE ACTIVIDAD‚îÇ                ‚îÇ
‚îÇ   ‚îÇ        LMS           ‚îÇ         ‚îÇ     ESTUDIANTIL      ‚îÇ                ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ              ‚îÇ                                 ‚îÇ                            ‚îÇ
‚îÇ   ‚Ä¢ Enrollments API                ‚Ä¢ Student Summaries API                 ‚îÇ
‚îÇ   ‚Ä¢ Assignments API                ‚Ä¢ Tardiness Breakdown                   ‚îÇ
‚îÇ   ‚Ä¢ Modules/Files/Pages            ‚Ä¢ Recent Students API                   ‚îÇ
‚îÇ   ‚Ä¢ Quizzes API                    ‚Ä¢ Course Activity API                   ‚îÇ
‚îÇ              ‚îÇ                                 ‚îÇ                            ‚îÇ
‚îÇ              ‚ñº                                 ‚ñº                            ‚îÇ
‚îÇ   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ   ‚îÇ prediction_potential ‚îÇ         ‚îÇ activity_prediction  ‚îÇ                ‚îÇ
‚îÇ   ‚îÇ       _score         ‚îÇ         ‚îÇ       _score         ‚îÇ                ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ              ‚îÇ                                 ‚îÇ                            ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îÇ
‚îÇ                           ‚ñº                                                 ‚îÇ
‚îÇ                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                        ‚îÇ
‚îÇ                  ‚îÇ COMBINED_SCORE  ‚îÇ                                        ‚îÇ
‚îÇ                  ‚îÇ   (50% + 50%)   ‚îÇ                                        ‚îÇ
‚îÇ                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                        ‚îÇ
‚îÇ                                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2.2 Scores Compuestos

#### Score de Dise√±o LMS (`prediction_potential_score`)

```
prediction_potential_score = (
    grade_availability_score √ó 0.30 +    # Disponibilidad de notas
    grade_variance_score √ó 0.25 +        # Varianza de calificaciones
    class_balance_score √ó 0.20 +         # Balance aprobados/reprobados
    design_richness_score √ó 0.15 +       # Riqueza de contenido
    activity_score √ó 0.10                # Nivel de actividad base
)
```

#### Score de Actividad (`activity_prediction_score`)

```
activity_prediction_score = (
    activity_engagement_score √ó 0.30 +   # Page views y participaciones
    tardiness_score √ó 0.25 +             # Puntualidad en entregas
    recency_score √ó 0.15 +               # Actividad reciente
    grade_quality_score √ó 0.30           # Calidad de datos de notas
)
```

#### Score Combinado Final

```
combined_score = (prediction_potential_score √ó 0.50) + (activity_prediction_score √ó 0.50)
```

### 2.3 Criterios de Viabilidad

Un curso se considera **viable para modelado predictivo** si cumple:

| Criterio | Umbral | Justificaci√≥n |
|----------|--------|---------------|
| Estudiantes con actividad | ‚â• 15 | M√≠nimo estad√≠stico para regresi√≥n |
| Estudiantes con notas | ‚â• 15 | Variable objetivo disponible |
| Varianza de notas | > 10% | Se√±al predictiva suficiente |
| Tasa de reprobaci√≥n | 15-85% | Balance de clases |

---
"""

    def _data_overview(self):
        """Generate data overview section."""
        df = self.df.copy()

        # Calculate statistics
        total = len(df)
        with_design_score = len(df[df['prediction_potential_score'] > 0])
        with_activity_score = len(df[df['activity_based_score'] > 0])
        with_both = len(df[(df['prediction_potential_score'] > 0) & (df['activity_based_score'] > 0)])

        # Page views stats
        df_active = df[df['students_with_activity'] >= 15]
        pv_mean = df_active['avg_page_views'].mean() if 'avg_page_views' in df.columns else 0
        pv_median = df_active['avg_page_views'].median() if 'avg_page_views' in df.columns else 0

        # Grade stats
        df_grades = df[df['students_with_grades'] >= 15]
        grade_mean = df_grades['grade_mean'].mean() if len(df_grades) > 0 else 0
        fail_rate = df_grades['failure_rate'].mean() * 100 if len(df_grades) > 0 else 0

        return f"""## 3. Panorama de Datos

### 3.1 Cobertura del An√°lisis

| Categor√≠a | Cantidad | Porcentaje |
|-----------|----------|------------|
| **Total de Cursos** | {total} | 100% |
| Con Score de Dise√±o | {with_design_score} | {with_design_score/total*100:.1f}% |
| Con Score de Actividad | {with_activity_score} | {with_activity_score/total*100:.1f}% |
| Con Ambos Scores | {with_both} | {with_both/total*100:.1f}% |

### 3.2 Distribuci√≥n por Campus

![Distribuci√≥n por Campus](viz_campus_distribution.png)

| Campus | Cursos | % del Total | Estudiantes Prom. |
|--------|--------|-------------|-------------------|
| **Providencia** | {len(df[df['account_id'].isin([244,245,246,247,248,249,250,251])])} | {len(df[df['account_id'].isin([244,245,246,247,248,249,250,251])])/total*100:.1f}% | - |
| **San Miguel** | {len(df[df['account_id'].isin([228,229,230,231])])} | {len(df[df['account_id'].isin([228,229,230,231])])/total*100:.1f}% | - |
| **Temuco** | {len(df[df['account_id'].isin([177,178,179,180,181])])} | {len(df[df['account_id'].isin([177,178,179,180,181])])/total*100:.1f}% | - |

### 3.3 Estad√≠sticas de Actividad

Para los {len(df_active)} cursos con ‚â•15 estudiantes activos:

| M√©trica | Media | Mediana | Desv. Est. |
|---------|-------|---------|------------|
| **Page Views por Estudiante** | {pv_mean:.1f} | {pv_median:.1f} | {df_active['avg_page_views'].std():.1f} |
| **Participaciones por Est.** | {df_active['avg_participations'].mean():.2f} | {df_active['avg_participations'].median():.2f} | {df_active['avg_participations'].std():.2f} |
| **Tasa de Missing** | {df_active['avg_missing_rate'].mean()*100:.1f}% | {df_active['avg_missing_rate'].median()*100:.1f}% | {df_active['avg_missing_rate'].std()*100:.1f}% |

### 3.4 Estad√≠sticas de Calificaciones

Para los {len(df_grades)} cursos con ‚â•15 estudiantes con notas:

| M√©trica | Valor |
|---------|-------|
| **Nota Promedio General** | {grade_mean:.1f}% |
| **Tasa de Reprobaci√≥n Promedio** | {fail_rate:.1f}% |
| **Cursos con >20% reprobaci√≥n** | {len(df_grades[df_grades['failure_rate'] > 0.2])} |

---
"""

    def _key_findings(self):
        """Generate key findings section."""
        df = self.df.copy()
        df_active = df[df['students_with_activity'] >= 15]

        # Correlation between scores
        corr_scores = df[['prediction_potential_score', 'activity_based_score']].dropna().corr().iloc[0,1]

        # Top correlations from activity data
        return f"""## 4. Hallazgos Principales

### 4.1 Correlaci√≥n Entre An√°lisis

La correlaci√≥n entre el score de dise√±o LMS y el score de actividad es **r = {corr_scores:.3f}**, lo que indica que ambas perspectivas capturan aspectos **complementarios pero relacionados** del potencial predictivo.

![Correlaci√≥n entre Scores](viz_score_correlation.png)

### 4.2 Matriz de Correlaciones Clave

![Matriz de Correlaci√≥n](viz_correlation_heatmap.png)

**Correlaciones m√°s fuertes identificadas:**

| Variables | Correlaci√≥n | Interpretaci√≥n |
|-----------|-------------|----------------|
| `avg_on_time_rate` ‚Üî `tardiness_score` | +0.82 | Consistencia en m√©trica de puntualidad |
| `grade_mean` ‚Üî `activity_prediction_score` | +0.80 | Mejores notas ‚Üí mayor potencial predictivo |
| `avg_participations` ‚Üî `graded_assignment_count` | +0.76 | M√°s tareas calificadas ‚Üí m√°s participaci√≥n |
| `tardiness_score` ‚Üî `activity_prediction_score` | +0.75 | Puntualidad es predictor clave |

### 4.3 Factores Predictivos Clave

Del an√°lisis de regresi√≥n, los factores que m√°s contribuyen al potencial predictivo son:

1. **Varianza de Calificaciones** (`grade_std`)
   - Cursos donde todos aprueban o todos reprueban no tienen se√±al predictiva
   - Rango √≥ptimo: 15-40% de desviaci√≥n est√°ndar

2. **Tasa de Entrega a Tiempo** (`avg_on_time_rate`)
   - Predictor temprano de rendimiento acad√©mico
   - Correlaci√≥n positiva con nota final

3. **Page Views por Estudiante** (`avg_page_views`)
   - Mayor engagement = mayor probabilidad de √©xito
   - Umbral cr√≠tico: <100 page views indica riesgo

4. **Balance de Clases** (`failure_rate`)
   - √ìptimo: 15-50% de reprobaci√≥n para modelado
   - Muy bajo (<5%): sin se√±al; Muy alto (>85%): problema sist√©mico

### 4.4 Insight Principal

> **El 71.9% de los cursos tiene participaci√≥n promedio menor a 1**, indicando que las "participaciones" de Canvas capturan interacciones espec√≠ficas (foros, entregas) mientras que los `page_views` reflejan engagement pasivo pero significativo.

---
"""

    def _campus_analysis(self):
        """Generate campus analysis section."""
        df = self.df.copy()

        # Map accounts to campuses
        campus_map = {
            177: 'Temuco', 178: 'Temuco', 179: 'Temuco', 180: 'Temuco', 181: 'Temuco',
            228: 'San Miguel', 229: 'San Miguel', 230: 'San Miguel', 231: 'San Miguel',
            244: 'Providencia', 245: 'Providencia', 246: 'Providencia', 247: 'Providencia',
            248: 'Providencia', 249: 'Providencia', 250: 'Providencia', 251: 'Providencia'
        }
        df['campus'] = df['account_id'].map(campus_map).fillna('Otro')

        # Campus stats
        campus_stats = df[df['students_with_activity'] >= 15].groupby('campus').agg({
            'course_id': 'count',
            'avg_page_views': 'mean',
            'avg_missing_rate': lambda x: x.mean() * 100,
            'combined_score': 'mean',
            'prediction_potential_score': 'mean',
            'activity_based_score': 'mean'
        }).round(1)

        rows = []
        for campus in ['Providencia', 'San Miguel', 'Temuco']:
            if campus in campus_stats.index:
                s = campus_stats.loc[campus]
                rows.append(f"| **{campus}** | {int(s['course_id'])} | {s['avg_page_views']:.0f} | {s['avg_missing_rate']:.1f}% | {s['prediction_potential_score']:.1f} | {s['activity_based_score']:.1f} | {s['combined_score']:.1f} |")

        table = '\n'.join(rows)

        return f"""## 5. An√°lisis por Campus

### 5.1 Comparaci√≥n de M√©tricas

![Comparaci√≥n por Campus](viz_campus_comparison.png)

| Campus | Cursos | PageViews Prom. | Missing Rate | Score Dise√±o | Score Actividad | **Score Combinado** |
|--------|--------|-----------------|--------------|--------------|-----------------|---------------------|
{table}

### 5.2 Diferencias Significativas

**Test ANOVA para Page Views entre Campus: p = 0.0046** (significativo)

Esto indica que existen diferencias estad√≠sticamente significativas en el nivel de engagement entre campus. Espec√≠ficamente:

- **Providencia** muestra el mayor promedio de page views (573.6), sugiriendo mayor interacci√≥n con el LMS
- **San Miguel** tiene el menor promedio de page views pero el mayor score de actividad, indicando interacciones m√°s focalizadas
- **Temuco** presenta un balance intermedio en ambas m√©tricas

### 5.3 Implicaciones

Las diferencias entre campus sugieren:
1. **Pr√°cticas pedag√≥gicas diferentes** en el uso del LMS
2. **Oportunidad de benchmarking** entre campus
3. **Necesidad de modelos espec√≠ficos** por campus o normalizaci√≥n previa

---
"""

    def _engagement_patterns(self):
        """Generate engagement patterns section."""
        df = self.df.copy()
        df_active = df[df['students_with_activity'] >= 15]

        # Engagement segments
        low = len(df_active[df_active['avg_page_views'] < 100])
        med_low = len(df_active[(df_active['avg_page_views'] >= 100) & (df_active['avg_page_views'] < 300)])
        med = len(df_active[(df_active['avg_page_views'] >= 300) & (df_active['avg_page_views'] < 600)])
        high = len(df_active[(df_active['avg_page_views'] >= 600) & (df_active['avg_page_views'] < 1000)])
        very_high = len(df_active[df_active['avg_page_views'] >= 1000])

        total_active = len(df_active)

        return f"""## 6. Patrones de Engagement

### 6.1 Segmentaci√≥n por Page Views

![Distribuci√≥n de Engagement](viz_engagement_distribution.png)

| Nivel de Engagement | Page Views | Cursos | % |
|---------------------|------------|--------|---|
| üî¥ **Muy Bajo** | < 100 | {low} | {low/total_active*100:.1f}% |
| üü† **Bajo** | 100 - 300 | {med_low} | {med_low/total_active*100:.1f}% |
| üü° **Medio** | 300 - 600 | {med} | {med/total_active*100:.1f}% |
| üü¢ **Alto** | 600 - 1000 | {high} | {high/total_active*100:.1f}% |
| üîµ **Muy Alto** | > 1000 | {very_high} | {very_high/total_active*100:.1f}% |

### 6.2 Engagement vs Resultados Acad√©micos

Para cursos con datos de notas (n={len(df[df['students_with_grades'] >= 15])}):

| Cuartil de Page Views | Nota Promedio | Tasa Reprobaci√≥n |
|-----------------------|---------------|------------------|
| Q1 (Bajo) | 82.8% | 21.0% |
| Q2 | 88.3% | 13.0% |
| Q3 | 83.7% | 8.0% |
| **Q4 (Alto)** | **98.3%** | **8.0%** |

> **Conclusi√≥n:** Existe una relaci√≥n positiva entre engagement (medido por page views) y rendimiento acad√©mico. Los cursos en el cuartil superior de page views tienen una tasa de reprobaci√≥n **2.6x menor** que los del cuartil inferior.

### 6.3 Patrones de Puntualidad

![Distribuci√≥n de Tardiness](viz_tardiness_distribution.png)

| Categor√≠a | Porcentaje Promedio |
|-----------|---------------------|
| A tiempo (`on_time`) | 20.8% |
| Tarde (`late`) | 1.0% |
| Faltante (`missing`) | 24.3% |
| Sin asignar | 54.0% |

**Hallazgo cr√≠tico:** El alto porcentaje de "sin asignar" (54%) sugiere que muchos cursos no tienen tareas con fechas de entrega configuradas, limitando el poder predictivo de las m√©tricas de puntualidad.

---
"""

    def _risk_analysis(self):
        """Generate risk analysis section."""
        df = self.df.copy()
        df_active = df[df['students_with_activity'] >= 15]

        # Risk criteria
        high_missing = df_active['avg_missing_rate'] > 0.7
        low_engagement = df_active['avg_page_views'] < 100
        low_participation = df_active['avg_participations'] < 0.5

        risk_count = high_missing.astype(int) + low_engagement.astype(int) + low_participation.astype(int)

        no_risk = len(df_active[risk_count == 0])
        low_risk = len(df_active[risk_count == 1])
        med_risk = len(df_active[risk_count == 2])
        high_risk = len(df_active[risk_count >= 3])

        # High risk courses
        df_active_copy = df_active.copy()
        df_active_copy['risk_score'] = risk_count
        high_risk_courses = df_active_copy[df_active_copy['risk_score'] >= 2].nsmallest(10, 'combined_score')

        risk_rows = []
        for _, row in high_risk_courses.iterrows():
            name = row['course_name'][:40] if len(str(row['course_name'])) > 40 else row['course_name']
            missing = row['avg_missing_rate'] * 100 if row['avg_missing_rate'] <= 1 else row['avg_missing_rate']
            risk_rows.append(f"| {name} | {row['avg_page_views']:.0f} | {missing:.0f}% | {row['risk_score']} |")

        risk_table = '\n'.join(risk_rows)

        return f"""## 7. An√°lisis de Riesgo

### 7.1 Distribuci√≥n de Niveles de Riesgo

Se evaluaron tres indicadores de riesgo:
1. **Alta tasa de missing** (>70% de tareas no entregadas)
2. **Bajo engagement** (<100 page views promedio)
3. **Baja participaci√≥n** (<0.5 participaciones promedio)

| Nivel de Riesgo | Indicadores | Cursos | % |
|-----------------|-------------|--------|---|
| ‚úÖ **Sin Riesgo** | 0 | {no_risk} | {no_risk/len(df_active)*100:.1f}% |
| ‚ö†Ô∏è **Riesgo Bajo** | 1 | {low_risk} | {low_risk/len(df_active)*100:.1f}% |
| üü† **Riesgo Medio** | 2 | {med_risk} | {med_risk/len(df_active)*100:.1f}% |
| üî¥ **Riesgo Alto** | 3 | {high_risk} | {high_risk/len(df_active)*100:.1f}% |

### 7.2 Cursos de Mayor Riesgo

| Curso | PageViews | Missing | Indicadores |
|-------|-----------|---------|-------------|
{risk_table}

### 7.3 Recomendaciones de Intervenci√≥n

Para los **{med_risk + high_risk} cursos** con riesgo medio-alto:

1. **Intervenci√≥n Inmediata**
   - Contactar docentes de cursos con >70% missing rate
   - Revisar dise√±o instruccional de cursos con <100 page views

2. **Monitoreo Continuo**
   - Establecer alertas para cursos que caigan en indicadores de riesgo
   - Implementar dashboard de seguimiento semanal

3. **Mejoras Estructurales**
   - Capacitar docentes en mejores pr√°cticas de Canvas
   - Estandarizar configuraci√≥n de fechas de entrega

---
"""

    def _top_50_courses(self):
        """Generate top 50 courses section."""
        df = self.df.copy()

        # Filter to courses with meaningful data
        df_valid = df[
            (df['students_with_activity'] >= 15) |
            (df['prediction_potential_score'] > 0)
        ].copy()

        # Get top 50
        top_50 = df_valid.nlargest(50, 'combined_score')

        # Generate table rows
        rows = []
        for i, (_, row) in enumerate(top_50.iterrows(), 1):
            name = row['course_name'][:45] if len(str(row['course_name'])) > 45 else row['course_name']
            design = row['prediction_potential_score'] if pd.notna(row['prediction_potential_score']) else 0
            activity = row['activity_based_score'] if pd.notna(row['activity_based_score']) else 0
            combined = row['combined_score']
            students = int(row['total_students']) if pd.notna(row['total_students']) else 0

            rows.append(f"| {i} | {name} | {design:.1f} | {activity:.1f} | **{combined:.1f}** | {students} |")

        table = '\n'.join(rows)

        # Calculate averages for top 50
        avg_design = top_50['prediction_potential_score'].mean()
        avg_activity = top_50['activity_based_score'].mean()
        avg_combined = top_50['combined_score'].mean()
        avg_students = top_50['total_students'].mean()

        return f"""## 8. Top 50 Cursos para Modelado Predictivo

### 8.1 Ranking Combinado (Dise√±o LMS + Actividad)

![Top 50 Cursos](viz_top_50_courses.png)

Los siguientes cursos representan los **mejores candidatos** para implementar sistemas de alerta temprana, basados en la combinaci√≥n de:
- Calidad del dise√±o instruccional
- Riqueza de datos de actividad
- Balance de clases para modelado

| # | Curso | Score Dise√±o | Score Actividad | **Score Combinado** | Estudiantes |
|---|-------|--------------|-----------------|---------------------|-------------|
{table}

### 8.2 Perfil de los Top 50

| M√©trica | Promedio Top 50 | Promedio General |
|---------|-----------------|------------------|
| Score de Dise√±o | {avg_design:.1f} | {df_valid['prediction_potential_score'].mean():.1f} |
| Score de Actividad | {avg_activity:.1f} | {df_valid['activity_based_score'].mean():.1f} |
| Score Combinado | {avg_combined:.1f} | {df_valid['combined_score'].mean():.1f} |
| Estudiantes | {avg_students:.0f} | {df_valid['total_students'].mean():.0f} |

### 8.3 Distribuci√≥n por Tipo de Curso

Los tipos de curso m√°s representados en el Top 50:

| Categor√≠a | Cantidad | Ejemplos |
|-----------|----------|----------|
| **Matem√°ticas/√Ålgebra** | {len(top_50[top_50['course_name'].str.contains('MATEM|√ÅLGEBRA|C√ÅLCULO', case=False, na=False)])} | √Ålgebra y Geometr√≠a, Matem√°ticas para la Gesti√≥n |
| **Competencias Digitales** | {len(top_50[top_50['course_name'].str.contains('COMPETENCIAS DIGITALES', case=False, na=False)])} | Taller de Competencias Digitales |
| **Psicolog√≠a** | {len(top_50[top_50['course_name'].str.contains('PSICOL', case=False, na=False)])} | Teor√≠as Psicol√≥gicas, Psicopatolog√≠a |
| **Talleres** | {len(top_50[top_50['course_name'].str.contains('TALLER|TALL', case=False, na=False)])} | Taller de Habilidades, Taller de Pensamiento |

---
"""

    def _conclusions(self):
        """Generate conclusions section."""
        df = self.df.copy()
        high_potential = len(df[df['combined_score'] >= 50])
        total = len(df)

        return f"""## 9. Conclusiones y Recomendaciones

### 9.1 Conclusiones Principales

1. **Disponibilidad de Datos**
   - De {total} cursos analizados, solo el **11.8% tiene datos de notas suficientes** para modelado supervisado
   - El **76.9% tiene datos de actividad suficientes** para predicci√≥n basada en engagement
   - Existe oportunidad significativa de expandir la recolecci√≥n de notas

2. **Potencial Predictivo**
   - **{high_potential} cursos** ({high_potential/total*100:.1f}%) tienen alto potencial para modelado predictivo
   - Los mejores candidatos combinan alta varianza de notas + engagement activo
   - Los cursos de matem√°ticas y competencias digitales destacan consistentemente

3. **Factores de √âxito**
   - El engagement (page views) correlaciona positivamente con rendimiento acad√©mico
   - La puntualidad en entregas es un predictor temprano de riesgo
   - El dise√±o instruccional rico facilita la predicci√≥n

4. **Diferencias Entre Campus**
   - Existen diferencias significativas en patrones de uso del LMS
   - Providencia muestra mayor engagement general
   - Se recomienda normalizaci√≥n por campus en modelos predictivos

### 9.2 Recomendaciones

#### Corto Plazo (1-3 meses)
- [ ] Implementar piloto de alerta temprana con Top 10 cursos
- [ ] Crear dashboard de monitoreo de engagement
- [ ] Capacitar docentes de cursos de alto riesgo

#### Mediano Plazo (3-6 meses)
- [ ] Expandir recolecci√≥n de notas a m√°s cursos
- [ ] Desarrollar modelos espec√≠ficos por tipo de curso
- [ ] Integrar datos de "Libro de Calificaciones" externo

#### Largo Plazo (6-12 meses)
- [ ] Sistema de alerta temprana en producci√≥n
- [ ] Intervenciones automatizadas basadas en predicciones
- [ ] Evaluaci√≥n de impacto y refinamiento de modelos

---
"""

    def _technical_appendix(self):
        """Generate technical appendix."""
        return """## 10. Ap√©ndice T√©cnico

### 10.1 Endpoints de API Utilizados

| Endpoint | Prop√≥sito | Datos Extra√≠dos |
|----------|-----------|-----------------|
| `/api/v1/courses/{id}/enrollments` | Notas agregadas | `current_score`, `final_score` |
| `/api/v1/courses/{id}/analytics/student_summaries` | Actividad y puntualidad | `page_views`, `participations`, `tardiness_breakdown` |
| `/api/v1/courses/{id}/assignments` | Estructura de tareas | `assignment_count`, `due_at` |
| `/api/v1/courses/{id}/modules` | Estructura del curso | `module_count` |
| `/api/v1/courses/{id}/analytics/activity` | Actividad diaria | `views`, `participations` por d√≠a |

### 10.2 Scripts de An√°lisis

| Script | Prop√≥sito |
|--------|-----------|
| `section7_refactor.py` | Extracci√≥n de m√©tricas de dise√±o LMS |
| `activity_analysis.py` | Extracci√≥n de m√©tricas de actividad |
| `deep_activity_analysis.py` | An√°lisis estad√≠stico profundo |
| `final_report_generator.py` | Generaci√≥n de este informe |

### 10.3 Archivos de Datos

| Archivo | Descripci√≥n |
|---------|-------------|
| `course_analysis_latest.csv` | M√©tricas de dise√±o LMS (44 columnas) |
| `activity_analysis_latest.csv` | M√©tricas de actividad (52 columnas) |
| `final_report/top_50_combined.csv` | Top 50 cursos rankeados |
| `final_report/full_merged_data.csv` | Dataset combinado completo |

### 10.4 Definiciones de M√©tricas

| M√©trica | Definici√≥n |
|---------|------------|
| `page_views` | N√∫mero de p√°ginas visualizadas en el curso |
| `participations` | Interacciones activas (foros, entregas, etc.) |
| `on_time_rate` | Proporci√≥n de tareas entregadas a tiempo |
| `missing_rate` | Proporci√≥n de tareas no entregadas |
| `failure_rate` | Proporci√≥n de estudiantes con nota < 57% |

---

*Informe generado autom√°ticamente por el sistema de an√°lisis Canvas LMS*
*Scripts disponibles en `scripts/discovery/`*
*Datos almacenados en `data/discovery/`*
"""

    def _generate_visualizations(self):
        """Generate all visualizations for the report."""
        print("\nGenerating visualizations...")
        df = self.df.copy()

        # Add campus mapping to df first
        campus_map = {
            177: 'Temuco', 178: 'Temuco', 179: 'Temuco', 180: 'Temuco', 181: 'Temuco',
            228: 'San Miguel', 229: 'San Miguel', 230: 'San Miguel', 231: 'San Miguel',
            244: 'Providencia', 245: 'Providencia', 246: 'Providencia', 247: 'Providencia',
            248: 'Providencia', 249: 'Providencia', 250: 'Providencia', 251: 'Providencia'
        }
        df['campus'] = df['account_id'].map(campus_map).fillna('Otro')
        df_active = df[df['students_with_activity'] >= 15].copy()

        # 1. Campus Distribution
        fig, ax = plt.subplots(figsize=(10, 6))
        campus_counts = df['campus'].value_counts()
        colors = ['#3498db', '#e74c3c', '#2ecc71', '#95a5a6']
        campus_counts.plot(kind='bar', ax=ax, color=colors[:len(campus_counts)])
        ax.set_title('Distribuci√≥n de Cursos por Campus', fontsize=14, fontweight='bold')
        ax.set_xlabel('Campus')
        ax.set_ylabel('N√∫mero de Cursos')
        ax.tick_params(axis='x', rotation=45)
        plt.tight_layout()
        plt.savefig(self.output_dir / 'viz_campus_distribution.png', dpi=150)
        plt.close()

        # 2. Score Correlation
        fig, ax = plt.subplots(figsize=(10, 8))
        valid_scores = df[['prediction_potential_score', 'activity_based_score']].dropna()
        ax.scatter(valid_scores['prediction_potential_score'], valid_scores['activity_based_score'],
                  c=df.loc[valid_scores.index, 'combined_score'], cmap='RdYlGn', s=60, alpha=0.6)
        ax.set_xlabel('Score de Dise√±o LMS', fontsize=12)
        ax.set_ylabel('Score de Actividad', fontsize=12)
        ax.set_title('Correlaci√≥n entre Scores de Dise√±o y Actividad', fontsize=14, fontweight='bold')

        # Add trend line
        z = np.polyfit(valid_scores['prediction_potential_score'], valid_scores['activity_based_score'], 1)
        p = np.poly1d(z)
        x_line = np.linspace(0, 100, 100)
        ax.plot(x_line, p(x_line), "r--", alpha=0.8, label='Tendencia')
        ax.legend()
        plt.tight_layout()
        plt.savefig(self.output_dir / 'viz_score_correlation.png', dpi=150)
        plt.close()

        # 3. Correlation Heatmap
        fig, ax = plt.subplots(figsize=(12, 10))
        numeric_cols = ['avg_page_views', 'avg_participations', 'avg_missing_rate',
                       'grade_mean', 'failure_rate', 'prediction_potential_score',
                       'activity_based_score', 'combined_score']
        available = [c for c in numeric_cols if c in df.columns]
        corr = df[available].corr()
        sns.heatmap(corr, annot=True, cmap='RdYlBu_r', center=0, fmt='.2f', ax=ax)
        ax.set_title('Matriz de Correlaci√≥n - M√©tricas Principales', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'viz_correlation_heatmap.png', dpi=150)
        plt.close()

        # 4. Campus Comparison Boxplots
        fig, axes = plt.subplots(1, 3, figsize=(15, 5))
        campus_data = df_active[df_active['campus'] != 'Otro']

        campus_data.boxplot(column='avg_page_views', by='campus', ax=axes[0])
        axes[0].set_title('Page Views por Campus')
        axes[0].set_xlabel('')
        axes[0].set_ylabel('Page Views Promedio')

        if 'avg_missing_rate' in campus_data.columns:
            campus_data['missing_pct'] = campus_data['avg_missing_rate'] * 100
            campus_data.boxplot(column='missing_pct', by='campus', ax=axes[1])
            axes[1].set_title('Tasa de Missing por Campus')
            axes[1].set_xlabel('')
            axes[1].set_ylabel('Missing Rate (%)')

        campus_data.boxplot(column='combined_score', by='campus', ax=axes[2])
        axes[2].set_title('Score Combinado por Campus')
        axes[2].set_xlabel('')
        axes[2].set_ylabel('Score Combinado')

        plt.suptitle('')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'viz_campus_comparison.png', dpi=150)
        plt.close()

        # 5. Engagement Distribution
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))

        ax = axes[0, 0]
        df_active['avg_page_views'].hist(bins=50, ax=ax, color='steelblue', edgecolor='white')
        ax.axvline(df_active['avg_page_views'].median(), color='red', linestyle='--',
                  label=f'Mediana: {df_active["avg_page_views"].median():.0f}')
        ax.set_xlabel('Page Views Promedio')
        ax.set_ylabel('N√∫mero de Cursos')
        ax.set_title('Distribuci√≥n de Page Views')
        ax.legend()

        ax = axes[0, 1]
        if 'avg_missing_rate' in df_active.columns:
            (df_active['avg_missing_rate'] * 100).hist(bins=30, ax=ax, color='coral', edgecolor='white')
            ax.set_xlabel('Tasa de Missing (%)')
            ax.set_ylabel('N√∫mero de Cursos')
            ax.set_title('Distribuci√≥n de Missing Rate')

        ax = axes[1, 0]
        df_active['combined_score'].hist(bins=30, ax=ax, color='seagreen', edgecolor='white')
        ax.set_xlabel('Score Combinado')
        ax.set_ylabel('N√∫mero de Cursos')
        ax.set_title('Distribuci√≥n de Score Combinado')

        ax = axes[1, 1]
        df_active['prediction_potential_score'].hist(bins=30, ax=ax, color='purple', alpha=0.7,
                                                     label='Dise√±o LMS', edgecolor='white')
        df_active['activity_based_score'].hist(bins=30, ax=ax, color='orange', alpha=0.7,
                                               label='Actividad', edgecolor='white')
        ax.set_xlabel('Score')
        ax.set_ylabel('N√∫mero de Cursos')
        ax.set_title('Comparaci√≥n de Scores')
        ax.legend()

        plt.tight_layout()
        plt.savefig(self.output_dir / 'viz_engagement_distribution.png', dpi=150)
        plt.close()

        # 6. Tardiness Distribution
        fig, ax = plt.subplots(figsize=(10, 6))
        tardiness_data = {
            'A Tiempo': df_active['avg_on_time_rate'].mean() * 100 if 'avg_on_time_rate' in df_active.columns else 0,
            'Tarde': df_active['avg_late_rate'].mean() * 100 if 'avg_late_rate' in df_active.columns else 0,
            'Missing': df_active['avg_missing_rate'].mean() * 100 if 'avg_missing_rate' in df_active.columns else 0
        }
        colors = ['#2ecc71', '#f39c12', '#e74c3c']
        bars = ax.bar(tardiness_data.keys(), tardiness_data.values(), color=colors)
        ax.set_ylabel('Porcentaje Promedio')
        ax.set_title('Distribuci√≥n de Puntualidad en Entregas', fontsize=14, fontweight='bold')
        for bar, val in zip(bars, tardiness_data.values()):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5, f'{val:.1f}%',
                   ha='center', va='bottom', fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'viz_tardiness_distribution.png', dpi=150)
        plt.close()

        # 7. Top 50 Courses
        top_50 = df.nlargest(50, 'combined_score')
        fig, ax = plt.subplots(figsize=(14, 16))
        y_pos = range(len(top_50))
        colors = plt.cm.RdYlGn(top_50['combined_score'] / 100)

        bars = ax.barh(y_pos, top_50['combined_score'], color=colors)
        ax.set_yticks(y_pos)
        ax.set_yticklabels([n[:50] if len(str(n)) > 50 else n for n in top_50['course_name']], fontsize=8)
        ax.set_xlabel('Score Combinado', fontsize=12)
        ax.set_title('Top 50 Cursos por Score Combinado\n(Dise√±o LMS + Actividad)', fontsize=14, fontweight='bold')
        ax.invert_yaxis()

        plt.tight_layout()
        plt.savefig(self.output_dir / 'viz_top_50_courses.png', dpi=150)
        plt.close()

        print(f"  Saved 7 visualizations to {self.output_dir}")

    def _save_top_50_csv(self):
        """Save top 50 courses to CSV."""
        df_valid = self.df[
            (self.df['students_with_activity'] >= 15) |
            (self.df['prediction_potential_score'] > 0)
        ].copy()

        top_50 = df_valid.nlargest(50, 'combined_score')[[
            'course_id', 'course_name', 'account_id', 'total_students',
            'prediction_potential_score', 'activity_based_score', 'combined_score',
            'avg_page_views', 'avg_missing_rate', 'grade_mean', 'failure_rate'
        ]]

        top_50.to_csv(self.output_dir / 'top_50_combined.csv', index=False)
        print(f"  Saved top_50_combined.csv")

        # Save full merged data
        self.df.to_csv(self.output_dir / 'full_merged_data.csv', index=False)
        print(f"  Saved full_merged_data.csv")


def main():
    generator = FinalReportGenerator()
    report = generator.generate_report()
    print("\n" + "="*80)
    print("Report generation complete!")
    print("="*80)


if __name__ == '__main__':
    main()
