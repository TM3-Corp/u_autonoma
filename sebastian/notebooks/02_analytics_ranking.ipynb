{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸ“Š Canvas Course-Level Analytics - Ranking Analysis\n\n**Objetivo:** Analizar mÃ©tricas de engagement a nivel de **CURSO** para identificar cursos con alto potencial para el sistema de alerta temprana.\n\n## Diferencia con anÃ¡lisis de cuenta\n- **Antes:** Agregado a nivel de cuenta/programa (PREGRADO, Providencia, etc.)\n- **Ahora:** MÃ©tricas individuales por curso (86005, 86676, etc.)\n\n## MÃ©tricas a Nivel de Curso\n- **Enrollments:** `n_students`, `grade_variance`, `pass_rate`\n- **Student Summaries:** `page_views`, `participations`, `tardiness`\n- **Resources:** `n_assignments`, `n_modules`, `n_quizzes`\n- **Assignment Analytics:** `missing_rate`, score distributions\n\n## Criterios de Ranking (para Early Warning)\n1. **Grade Variance** - Mayor varianza = mejor para predicciÃ³n\n2. **Pass Rate** - Ideal entre 20-80% \n3. **LMS Design** - MÃ¡s recursos = mÃ¡s seÃ±ales de engagement\n4. **Student Activity** - Page views y participations por estudiante\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup y ConfiguraciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API URL: https://uautonoma.test.instructure.com\n",
      "âœ… Token configurado: SÃ­\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# Cargar credenciales\n",
    "load_dotenv()\n",
    "\n",
    "API_URL = os.getenv('CANVAS_API_URL')\n",
    "API_TOKEN = os.getenv('CANVAS_API_TOKEN')\n",
    "headers = {'Authorization': f'Bearer {API_TOKEN}'}\n",
    "\n",
    "print(f\"âœ… API URL: {API_URL}\")\n",
    "print(f\"âœ… Token configurado: {'SÃ­' if API_TOKEN else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Funciones de API para Analytics a Nivel de Curso"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# FUNCIONES DE API - NIVEL DE CURSO\n# ============================================================\n\ndef get_courses_from_account(account_id, term_id=None, min_students=10):\n    \"\"\"\n    Obtiene cursos de una cuenta con filtro de estudiantes mÃ­nimos.\n    \n    GET /api/v1/accounts/{account_id}/courses\n    \"\"\"\n    params = {\n        'per_page': 100,\n        'include[]': ['total_students', 'term'],\n        'with_enrollments': True\n    }\n    if term_id:\n        params['enrollment_term_id'] = term_id\n    \n    courses = []\n    url = f'{API_URL}/api/v1/accounts/{account_id}/courses'\n    \n    while url:\n        r = requests.get(url, headers=headers, params=params)\n        if r.status_code != 200:\n            print(f\"Error {r.status_code} fetching courses from account {account_id}\")\n            break\n        \n        for course in r.json():\n            if course.get('total_students', 0) >= min_students:\n                courses.append({\n                    'course_id': course['id'],\n                    'course_name': course['name'],\n                    'total_students': course.get('total_students', 0),\n                    'term_name': course.get('term', {}).get('name', 'Unknown'),\n                    'term_id': course.get('enrollment_term_id'),\n                    'account_id': account_id\n                })\n        \n        # Pagination via Link header\n        url = r.links.get('next', {}).get('url')\n        params = {}  # URL already contains params\n        time.sleep(0.2)\n    \n    return sorted(courses, key=lambda x: x['total_students'], reverse=True)\n\n\ndef get_course_enrollments_with_grades(course_id):\n    \"\"\"\n    Obtiene enrollments con calificaciones.\n    \n    GET /api/v1/courses/{course_id}/enrollments\n    \"\"\"\n    r = requests.get(\n        f'{API_URL}/api/v1/courses/{course_id}/enrollments',\n        headers=headers,\n        params={\n            'type[]': 'StudentEnrollment',\n            'per_page': 100,\n            'include[]': ['grades', 'total_scores']\n        }\n    )\n    if r.status_code != 200:\n        return []\n    return r.json()\n\n\ndef get_course_student_summaries(course_id):\n    \"\"\"\n    Obtiene mÃ©tricas de actividad por estudiante.\n    \n    GET /api/v1/courses/{course_id}/analytics/student_summaries\n    \"\"\"\n    r = requests.get(\n        f'{API_URL}/api/v1/courses/{course_id}/analytics/student_summaries',\n        headers=headers,\n        params={'per_page': 100}\n    )\n    if r.status_code != 200:\n        return []\n    return r.json()\n\n\ndef get_course_assignments(course_id):\n    \"\"\"\n    Obtiene lista de assignments del curso.\n    \n    GET /api/v1/courses/{course_id}/assignments\n    \"\"\"\n    r = requests.get(\n        f'{API_URL}/api/v1/courses/{course_id}/assignments',\n        headers=headers,\n        params={'per_page': 100}\n    )\n    if r.status_code != 200:\n        return []\n    return r.json()\n\n\ndef get_course_modules(course_id):\n    \"\"\"\n    Obtiene mÃ³dulos del curso.\n    \n    GET /api/v1/courses/{course_id}/modules\n    \"\"\"\n    r = requests.get(\n        f'{API_URL}/api/v1/courses/{course_id}/modules',\n        headers=headers,\n        params={'per_page': 100}\n    )\n    if r.status_code != 200:\n        return []\n    return r.json()\n\n\ndef get_course_quizzes(course_id):\n    \"\"\"\n    Obtiene quizzes del curso.\n    \n    GET /api/v1/courses/{course_id}/quizzes\n    \"\"\"\n    r = requests.get(\n        f'{API_URL}/api/v1/courses/{course_id}/quizzes',\n        headers=headers,\n        params={'per_page': 100}\n    )\n    if r.status_code != 200:\n        return []\n    return r.json()\n\n\ndef get_course_assignment_analytics(course_id):\n    \"\"\"\n    Obtiene estadÃ­sticas de assignments (quartiles, tardiness).\n    \n    GET /api/v1/courses/{course_id}/analytics/assignments\n    \"\"\"\n    r = requests.get(\n        f'{API_URL}/api/v1/courses/{course_id}/analytics/assignments',\n        headers=headers\n    )\n    if r.status_code != 200:\n        return []\n    return r.json()\n\n\ndef get_enrollment_terms(account_id):\n    \"\"\"\n    Obtiene tÃ©rminos de matrÃ­cula disponibles.\n    \"\"\"\n    url = f\"{API_URL}/api/v1/accounts/{account_id}/terms\"\n    response = requests.get(url, headers=headers, params={'per_page': 50})\n    if response.status_code == 200:\n        return response.json().get('enrollment_terms', [])\n    return []\n\n\nprint(\"âœ… Funciones de API a nivel de curso definidas\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. ConfiguraciÃ³n de Cuentas y TÃ©rminos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Obtener tÃ©rminos disponibles\nterms = get_enrollment_terms(1)\n\nprint(\"ğŸ“… TÃ‰RMINOS DISPONIBLES\")\nprint(\"=\" * 50)\nterms_df = pd.DataFrame(terms)\nif not terms_df.empty:\n    display(terms_df[['id', 'name']].head(10))\n    \n# TÃ©rminos relevantes para anÃ¡lisis\nTERM_IDS = {\n    '1er_sem_2025': 322,\n    '2do_sem_2025': 336,\n    'bimestral_2025': 352\n}\nprint(f\"\\nğŸ“Œ TÃ©rminos principales: {TERM_IDS}\")\n\n# TÃ©rmino activo para anÃ¡lisis\nACTIVE_TERM_ID = 336  # 2do Semestre 2025\nprint(f\"ğŸ¯ TÃ©rmino activo para anÃ¡lisis: {ACTIVE_TERM_ID}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cuentas a escanear para obtener cursos\nACCOUNTS_TO_SCAN = {\n    'Ing_Control_Gestion': 719,      # Ya analizado - control\n    'Ing_Control_Gestion_Alt': 718,  # Alternativo\n    'Ing_Civil_Industrial': 730,     # IngenierÃ­a\n}\n\n# Para anÃ¡lisis mÃ¡s amplio, descomentar:\n# ACCOUNTS_TO_SCAN = {\n#     'Providencia': 176,              # Sede completa\n#     'Ing_Control_Gestion': 719,\n#     'Campus_Virtual_PG': 401,        # Postgrado\n# }\n\nprint(\"ğŸ›ï¸ CUENTAS A ESCANEAR\")\nprint(\"=\" * 50)\nfor name, acc_id in ACCOUNTS_TO_SCAN.items():\n    print(f\"  {acc_id}: {name}\")\n\n# ConfiguraciÃ³n de filtros\nMIN_STUDENTS = 15  # MÃ­nimo de estudiantes por curso\nprint(f\"\\nğŸ“Š Filtro: cursos con >= {MIN_STUDENTS} estudiantes\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Descubrimiento y AnÃ¡lisis de Cursos\n\nObtiene cursos de las cuentas configuradas y extrae mÃ©tricas a nivel de curso."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def analyze_course(course_id, course_name=None):\n    \"\"\"\n    Analiza un curso individual y extrae todas las mÃ©tricas relevantes.\n    \n    Retorna dict con:\n    - MÃ©tricas de calificaciones (grade_variance, pass_rate)\n    - MÃ©tricas de actividad (page_views, participations)\n    - MÃ©tricas de diseÃ±o LMS (n_assignments, n_modules, n_quizzes)\n    - MÃ©tricas de tardiness (on_time_rate, missing_rate)\n    \"\"\"\n    result = {\n        'course_id': course_id,\n        'course_name': course_name or f\"Course {course_id}\",\n        \n        # Grade metrics\n        'n_students_with_grades': 0,\n        'grade_mean': None,\n        'grade_std': None,\n        'grade_min': None,\n        'grade_max': None,\n        'pass_rate': None,\n        \n        # Activity metrics (aggregated from student summaries)\n        'total_page_views': 0,\n        'total_participations': 0,\n        'avg_page_views': 0,\n        'avg_participations': 0,\n        \n        # Tardiness metrics\n        'avg_on_time_rate': None,\n        'avg_missing_rate': None,\n        \n        # LMS Design metrics\n        'n_assignments': 0,\n        'n_modules': 0,\n        'n_quizzes': 0,\n        \n        # Assignment analytics\n        'assignments_with_scores': 0,\n        'avg_assignment_missing_rate': None,\n        \n        # Status\n        'has_grades': False,\n        'has_activity': False,\n        'recommendation': 'SKIP'\n    }\n    \n    # 1. Get enrollments with grades\n    enrollments = get_course_enrollments_with_grades(course_id)\n    grades = []\n    for e in enrollments:\n        final_score = e.get('grades', {}).get('final_score')\n        if final_score is not None:\n            grades.append(final_score)\n    \n    if len(grades) >= 5:  # Need at least 5 students with grades\n        result['has_grades'] = True\n        result['n_students_with_grades'] = len(grades)\n        result['grade_mean'] = np.mean(grades)\n        result['grade_std'] = np.std(grades)\n        result['grade_min'] = np.min(grades)\n        result['grade_max'] = np.max(grades)\n        result['pass_rate'] = sum(1 for g in grades if g >= 57) / len(grades)\n    \n    # 2. Get student summaries (activity)\n    summaries = get_course_student_summaries(course_id)\n    if summaries:\n        result['has_activity'] = True\n        \n        page_views = [s.get('page_views', 0) for s in summaries]\n        participations = [s.get('participations', 0) for s in summaries]\n        \n        result['total_page_views'] = sum(page_views)\n        result['total_participations'] = sum(participations)\n        result['avg_page_views'] = np.mean(page_views) if page_views else 0\n        result['avg_participations'] = np.mean(participations) if participations else 0\n        \n        # Tardiness breakdown\n        on_time_rates = []\n        missing_rates = []\n        for s in summaries:\n            tb = s.get('tardiness_breakdown', {})\n            total = tb.get('on_time', 0) + tb.get('late', 0) + tb.get('missing', 0)\n            if total > 0:\n                on_time_rates.append(tb.get('on_time', 0) / total)\n                missing_rates.append(tb.get('missing', 0) / total)\n        \n        if on_time_rates:\n            result['avg_on_time_rate'] = np.mean(on_time_rates)\n            result['avg_missing_rate'] = np.mean(missing_rates)\n    \n    # 3. Get LMS resources count\n    result['n_assignments'] = len(get_course_assignments(course_id))\n    result['n_modules'] = len(get_course_modules(course_id))\n    result['n_quizzes'] = len(get_course_quizzes(course_id))\n    \n    # 4. Get assignment analytics\n    assignment_analytics = get_course_assignment_analytics(course_id)\n    if assignment_analytics:\n        result['assignments_with_scores'] = len([a for a in assignment_analytics if a.get('median') is not None])\n        missing_rates = [a.get('tardiness_breakdown', {}).get('missing', 0) \n                        for a in assignment_analytics if a.get('tardiness_breakdown')]\n        if missing_rates:\n            result['avg_assignment_missing_rate'] = np.mean(missing_rates)\n    \n    # 5. Determine recommendation\n    if result['has_grades'] and result['grade_std'] and result['grade_std'] > 10:\n        if result['n_assignments'] >= 5 and result['pass_rate'] is not None:\n            if 0.2 <= result['pass_rate'] <= 0.8:\n                result['recommendation'] = 'HIGH POTENTIAL'\n            else:\n                result['recommendation'] = 'MEDIUM POTENTIAL'\n        elif result['n_assignments'] >= 3:\n            result['recommendation'] = 'MEDIUM POTENTIAL'\n        else:\n            result['recommendation'] = 'LOW - Few assignments'\n    elif result['has_grades']:\n        result['recommendation'] = 'LOW - Low grade variance'\n    else:\n        result['recommendation'] = 'SKIP - No grades'\n    \n    return result\n\n\nprint(\"âœ… FunciÃ³n de anÃ¡lisis de curso definida\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Descubrir cursos de las cuentas configuradas\nprint(\"ğŸ” DESCUBRIENDO CURSOS\")\nprint(\"=\" * 60)\n\nall_courses = []\n\nfor account_name, account_id in ACCOUNTS_TO_SCAN.items():\n    print(f\"\\nğŸ“‚ Escaneando {account_name} (ID: {account_id})...\")\n    courses = get_courses_from_account(account_id, term_id=ACTIVE_TERM_ID, min_students=MIN_STUDENTS)\n    print(f\"   Encontrados: {len(courses)} cursos con >= {MIN_STUDENTS} estudiantes\")\n    \n    for c in courses:\n        c['account_name'] = account_name\n    all_courses.extend(courses)\n\nprint(f\"\\nğŸ“Š TOTAL: {len(all_courses)} cursos para analizar\")\n\n# Mostrar primeros cursos\nif all_courses:\n    courses_df = pd.DataFrame(all_courses)\n    display(courses_df[['course_id', 'course_name', 'total_students', 'account_name']].head(15))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Analizar cada curso\nprint(\"ğŸ“Š ANALIZANDO CURSOS\")\nprint(\"=\" * 60)\n\ncourse_analyses = []\n\nfor i, course in enumerate(all_courses):\n    course_id = course['course_id']\n    course_name = course['course_name']\n    \n    print(f\"  [{i+1}/{len(all_courses)}] {course_id}: {course_name[:40]}...\", end=\" \")\n    \n    try:\n        analysis = analyze_course(course_id, course_name)\n        analysis['total_students'] = course['total_students']\n        analysis['account_name'] = course['account_name']\n        analysis['term_id'] = course.get('term_id')\n        course_analyses.append(analysis)\n        \n        status = \"âœ…\" if analysis['has_grades'] else \"âš ï¸\"\n        print(f\"{status} ({analysis['recommendation']})\")\n    except Exception as e:\n        print(f\"âŒ Error: {e}\")\n    \n    time.sleep(0.5)  # Rate limiting\n\nprint(f\"\\nğŸ“ˆ Cursos analizados: {len(course_analyses)}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Crear DataFrame con resultados\ncourses_df = pd.DataFrame(course_analyses)\n\n# Mostrar resumen\nprint(f\"ğŸ“Š RESUMEN DE ANÃLISIS\")\nprint(\"=\" * 60)\nprint(f\"Total cursos analizados: {len(courses_df)}\")\nprint(f\"Cursos con notas: {courses_df['has_grades'].sum()}\")\nprint(f\"Cursos con actividad: {courses_df['has_activity'].sum()}\")\n\nprint(\"\\nğŸ“ˆ DistribuciÃ³n por RecomendaciÃ³n:\")\nprint(courses_df['recommendation'].value_counts().to_string())\n\n# Mostrar columnas principales\ndisplay_cols = ['course_id', 'course_name', 'total_students', 'n_students_with_grades',\n                'grade_std', 'pass_rate', 'n_assignments', 'recommendation']\navailable_cols = [c for c in display_cols if c in courses_df.columns]\n\nprint(\"\\nğŸ“‹ Cursos con Mayor Potencial:\")\nhigh_potential = courses_df[courses_df['recommendation'].str.contains('HIGH|MEDIUM', na=False)]\nif not high_potential.empty:\n    display(high_potential[available_cols].head(10))\nelse:\n    print(\"No se encontraron cursos con alto potencial en esta bÃºsqueda.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. CÃ¡lculo de MÃ©tricas de Ranking a Nivel de Curso\n\nMÃ©tricas compuestas para determinar el potencial de cada curso para early warning."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_course_ranking_metrics(df):\n    \"\"\"\n    Calcula mÃ©tricas de ranking especÃ­ficas para Early Warning System.\n    \n    Criterios:\n    1. Grade Variance - Mayor varianza = mejor predicciÃ³n\n    2. Pass Rate - Ideal 20-80% (no todos aprueban/reprueban)\n    3. LMS Design Score - MÃ¡s recursos = mÃ¡s seÃ±ales\n    4. Activity Score - Engagement estudiantil\n    5. Data Quality - Completitud de datos\n    \"\"\"\n    df = df.copy()\n    \n    # 1. Grade Variance Score (normalizado)\n    grade_std = df['grade_std'].fillna(0)\n    df['grade_variance_score'] = grade_std / grade_std.max() if grade_std.max() > 0 else 0\n    \n    # 2. Pass Rate Score (penaliza extremos 0% y 100%)\n    # Ã“ptimo: 50%, decae hacia los extremos\n    pass_rate = df['pass_rate'].fillna(0.5)\n    df['pass_rate_score'] = 1 - np.abs(pass_rate - 0.5) * 2  # 1 at 50%, 0 at 0% or 100%\n    \n    # 3. LMS Design Score (combinaciÃ³n de recursos)\n    df['lms_design_score'] = (\n        df['n_assignments'].fillna(0) * 2 +  # Assignments mÃ¡s importantes\n        df['n_quizzes'].fillna(0) * 1.5 +\n        df['n_modules'].fillna(0) * 1\n    )\n    max_lms = df['lms_design_score'].max()\n    df['lms_design_score'] = df['lms_design_score'] / max_lms if max_lms > 0 else 0\n    \n    # 4. Activity Score (engagement per student)\n    df['activity_score'] = (\n        df['avg_page_views'].fillna(0) + \n        df['avg_participations'].fillna(0) * 10  # Participations mÃ¡s valiosas\n    )\n    max_activity = df['activity_score'].max()\n    df['activity_score'] = df['activity_score'] / max_activity if max_activity > 0 else 0\n    \n    # 5. Data Quality Score\n    df['data_quality_score'] = (\n        df['has_grades'].astype(int) * 0.4 +\n        df['has_activity'].astype(int) * 0.3 +\n        (df['n_students_with_grades'] >= 20).astype(int) * 0.3\n    )\n    \n    # 6. Composite Score for Early Warning\n    # Weighted combination focusing on prediction potential\n    df['ew_potential_score'] = (\n        df['grade_variance_score'] * 0.30 +      # 30% - Varianza de notas\n        df['pass_rate_score'] * 0.20 +           # 20% - Balance aprobados/reprobados\n        df['lms_design_score'] * 0.20 +          # 20% - DiseÃ±o del curso\n        df['activity_score'] * 0.15 +            # 15% - Actividad estudiantil\n        df['data_quality_score'] * 0.15          # 15% - Calidad de datos\n    )\n    \n    return df\n\n\n# Calcular mÃ©tricas solo para cursos con datos\nif not courses_df.empty:\n    courses_with_metrics = calculate_course_ranking_metrics(courses_df)\n    \n    print(\"ğŸ“Š MÃ‰TRICAS DE RANKING CALCULADAS\")\n    print(\"=\" * 60)\n    \n    metric_cols = ['course_name', 'grade_variance_score', 'pass_rate_score', \n                   'lms_design_score', 'activity_score', 'ew_potential_score']\n    available_cols = [c for c in metric_cols if c in courses_with_metrics.columns]\n    \n    # Top 10 por potencial\n    top_courses = courses_with_metrics.nlargest(10, 'ew_potential_score')\n    display(top_courses[available_cols].round(3))\nelse:\n    print(\"âš ï¸ No hay cursos para calcular mÃ©tricas\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6. Visualizaciones a Nivel de Curso"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ConfiguraciÃ³n de figuras\nfig_dir = '../data/analytics/'\nos.makedirs(fig_dir, exist_ok=True)\n\nif not courses_df.empty and 'ew_potential_score' in courses_with_metrics.columns:\n    \n    # 6.1 DistribuciÃ³n de Pass Rate\n    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n    \n    # Plot 1: Histograma de Pass Rate\n    ax1 = axes[0]\n    pass_rates = courses_with_metrics['pass_rate'].dropna()\n    if len(pass_rates) > 0:\n        ax1.hist(pass_rates, bins=10, color='steelblue', edgecolor='black', alpha=0.7)\n        ax1.axvline(x=0.57, color='red', linestyle='--', label='Umbral aprobaciÃ³n (57%)')\n        ax1.axvspan(0.2, 0.8, alpha=0.2, color='green', label='Rango ideal (20-80%)')\n        ax1.set_xlabel('Pass Rate', fontsize=11)\n        ax1.set_ylabel('NÃºmero de Cursos', fontsize=11)\n        ax1.set_title('ğŸ“Š DistribuciÃ³n de Tasa de AprobaciÃ³n', fontsize=12, fontweight='bold')\n        ax1.legend()\n    \n    # Plot 2: Histograma de Grade Variance\n    ax2 = axes[1]\n    grade_stds = courses_with_metrics['grade_std'].dropna()\n    if len(grade_stds) > 0:\n        ax2.hist(grade_stds, bins=10, color='coral', edgecolor='black', alpha=0.7)\n        ax2.axvline(x=10, color='green', linestyle='--', label='MÃ­nimo Ãºtil (Ïƒ=10)')\n        ax2.set_xlabel('DesviaciÃ³n EstÃ¡ndar de Notas', fontsize=11)\n        ax2.set_ylabel('NÃºmero de Cursos', fontsize=11)\n        ax2.set_title('ğŸ“ˆ DistribuciÃ³n de Varianza de Notas', fontsize=12, fontweight='bold')\n        ax2.legend()\n    \n    plt.tight_layout()\n    plt.savefig(f'{fig_dir}viz_01_course_distributions.png', dpi=150, bbox_inches='tight')\n    plt.show()\n    print(f\"âœ… Guardado: {fig_dir}viz_01_course_distributions.png\")\nelse:\n    print(\"âš ï¸ No hay datos suficientes para visualizar\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 6.2 Scatter: Grade Variance vs Pass Rate (identificar cursos ideales)\nif not courses_df.empty and 'grade_std' in courses_with_metrics.columns:\n    fig, ax = plt.subplots(figsize=(12, 8))\n    \n    # Filtrar cursos con datos\n    plot_data = courses_with_metrics[\n        courses_with_metrics['grade_std'].notna() & \n        courses_with_metrics['pass_rate'].notna()\n    ].copy()\n    \n    if len(plot_data) > 0:\n        # Scatter plot\n        scatter = ax.scatter(\n            plot_data['pass_rate'],\n            plot_data['grade_std'],\n            s=plot_data['total_students'] * 3 + 50,  # TamaÃ±o por estudiantes\n            c=plot_data['ew_potential_score'],\n            cmap='RdYlGn',\n            alpha=0.7,\n            edgecolors='black',\n            linewidth=1\n        )\n        \n        # Zona ideal\n        ax.axhspan(10, plot_data['grade_std'].max() + 5, xmin=0.2, xmax=0.8, \n                   alpha=0.15, color='green', label='Zona ideal')\n        ax.axhline(y=10, color='green', linestyle='--', alpha=0.5)\n        ax.axvline(x=0.2, color='green', linestyle='--', alpha=0.5)\n        ax.axvline(x=0.8, color='green', linestyle='--', alpha=0.5)\n        \n        # Etiquetas para top cursos\n        top_5 = plot_data.nlargest(5, 'ew_potential_score')\n        for _, row in top_5.iterrows():\n            ax.annotate(\n                row['course_name'][:20],\n                (row['pass_rate'], row['grade_std']),\n                fontsize=8, alpha=0.8,\n                xytext=(5, 5), textcoords='offset points'\n            )\n        \n        ax.set_xlabel('Tasa de AprobaciÃ³n (Pass Rate)', fontsize=11)\n        ax.set_ylabel('DesviaciÃ³n EstÃ¡ndar de Notas', fontsize=11)\n        ax.set_title('ğŸ¯ IdentificaciÃ³n de Cursos con Alto Potencial para Early Warning', \n                     fontsize=13, fontweight='bold')\n        \n        cbar = plt.colorbar(scatter, ax=ax)\n        cbar.set_label('EW Potential Score', fontsize=10)\n        \n        ax.legend(loc='upper right')\n        \n        plt.tight_layout()\n        plt.savefig(f'{fig_dir}viz_02_course_scatter.png', dpi=150, bbox_inches='tight')\n        plt.show()\n        print(f\"âœ… Guardado: {fig_dir}viz_02_course_scatter.png\")\nelse:\n    print(\"âš ï¸ No hay datos suficientes para scatter plot\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 6.3 Top 15 Cursos por EW Potential Score\nif not courses_df.empty and 'ew_potential_score' in courses_with_metrics.columns:\n    fig, ax = plt.subplots(figsize=(12, 10))\n    \n    # Top 15 cursos\n    top_courses = courses_with_metrics.nlargest(15, 'ew_potential_score')\n    \n    if len(top_courses) > 0:\n        # Crear labels mÃ¡s legibles\n        labels = [f\"{row['course_id']}: {row['course_name'][:35]}\" \n                  for _, row in top_courses.iterrows()]\n        \n        colors = plt.cm.RdYlGn(top_courses['ew_potential_score'] / top_courses['ew_potential_score'].max())\n        \n        bars = ax.barh(range(len(top_courses)), top_courses['ew_potential_score'], color=colors)\n        ax.set_yticks(range(len(top_courses)))\n        ax.set_yticklabels(labels, fontsize=9)\n        ax.invert_yaxis()\n        \n        ax.set_xlabel('EW Potential Score', fontsize=11)\n        ax.set_title('ğŸ† Top 15 Cursos por Potencial para Early Warning', \n                     fontsize=13, fontweight='bold')\n        \n        # Agregar valores\n        for bar, score in zip(bars, top_courses['ew_potential_score']):\n            ax.text(score + 0.01, bar.get_y() + bar.get_height()/2,\n                    f'{score:.3f}', va='center', fontsize=9)\n        \n        plt.tight_layout()\n        plt.savefig(f'{fig_dir}viz_03_top_courses_ranking.png', dpi=150, bbox_inches='tight')\n        plt.show()\n        print(f\"âœ… Guardado: {fig_dir}viz_03_top_courses_ranking.png\")\nelse:\n    print(\"âš ï¸ No hay datos suficientes para ranking\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 6.4 Actividad vs Resultados AcadÃ©micos\nif not courses_df.empty and 'avg_page_views' in courses_with_metrics.columns:\n    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n    \n    plot_data = courses_with_metrics[\n        courses_with_metrics['avg_page_views'].notna() & \n        courses_with_metrics['pass_rate'].notna()\n    ].copy()\n    \n    if len(plot_data) > 0:\n        # Plot 1: Page Views vs Pass Rate\n        ax1 = axes[0]\n        ax1.scatter(\n            plot_data['avg_page_views'],\n            plot_data['pass_rate'],\n            s=100, alpha=0.6, c='steelblue', edgecolors='black'\n        )\n        ax1.set_xlabel('Promedio Page Views por Estudiante', fontsize=11)\n        ax1.set_ylabel('Tasa de AprobaciÃ³n', fontsize=11)\n        ax1.set_title('ğŸ“ˆ Actividad vs AprobaciÃ³n', fontsize=12, fontweight='bold')\n        \n        # LÃ­nea de tendencia\n        if len(plot_data) > 2:\n            z = np.polyfit(plot_data['avg_page_views'], plot_data['pass_rate'], 1)\n            p = np.poly1d(z)\n            x_line = np.linspace(plot_data['avg_page_views'].min(), \n                                 plot_data['avg_page_views'].max(), 100)\n            ax1.plot(x_line, p(x_line), 'r--', alpha=0.8, label='Tendencia')\n            ax1.legend()\n        \n        # Plot 2: Participations vs Grade Mean\n        ax2 = axes[1]\n        plot_data2 = courses_with_metrics[\n            courses_with_metrics['avg_participations'].notna() & \n            courses_with_metrics['grade_mean'].notna()\n        ]\n        if len(plot_data2) > 0:\n            ax2.scatter(\n                plot_data2['avg_participations'],\n                plot_data2['grade_mean'],\n                s=100, alpha=0.6, c='coral', edgecolors='black'\n            )\n            ax2.set_xlabel('Promedio Participaciones por Estudiante', fontsize=11)\n            ax2.set_ylabel('Nota Promedio del Curso', fontsize=11)\n            ax2.set_title('ğŸ’¬ ParticipaciÃ³n vs Rendimiento', fontsize=12, fontweight='bold')\n            \n            if len(plot_data2) > 2:\n                z = np.polyfit(plot_data2['avg_participations'], plot_data2['grade_mean'], 1)\n                p = np.poly1d(z)\n                x_line = np.linspace(plot_data2['avg_participations'].min(), \n                                     plot_data2['avg_participations'].max(), 100)\n                ax2.plot(x_line, p(x_line), 'r--', alpha=0.8, label='Tendencia')\n                ax2.legend()\n        \n        plt.tight_layout()\n        plt.savefig(f'{fig_dir}viz_04_activity_vs_grades.png', dpi=150, bbox_inches='tight')\n        plt.show()\n        print(f\"âœ… Guardado: {fig_dir}viz_04_activity_vs_grades.png\")\nelse:\n    print(\"âš ï¸ No hay datos de actividad para visualizar\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 6.5 Heatmap: LMS Design vs Outcomes (Top 10 cursos)\nif not courses_df.empty and len(courses_with_metrics) >= 3:\n    fig, ax = plt.subplots(figsize=(12, 8))\n    \n    # Top 10 cursos por potencial\n    top_10 = courses_with_metrics.nlargest(10, 'ew_potential_score')\n    \n    # MÃ©tricas para heatmap\n    heatmap_cols = ['n_assignments', 'n_modules', 'n_quizzes', \n                    'avg_page_views', 'avg_participations', 'pass_rate', 'grade_std']\n    available_cols = [c for c in heatmap_cols if c in top_10.columns]\n    \n    if len(available_cols) >= 3:\n        heatmap_data = top_10[available_cols].copy()\n        \n        # Normalizar cada columna 0-1\n        for col in available_cols:\n            max_val = heatmap_data[col].max()\n            if max_val > 0:\n                heatmap_data[col] = heatmap_data[col] / max_val\n        \n        heatmap_data.index = [f\"{row['course_id']}: {row['course_name'][:25]}\" \n                              for _, row in top_10.iterrows()]\n        \n        sns.heatmap(heatmap_data, annot=True, fmt='.2f', cmap='YlOrRd',\n                    linewidths=0.5, ax=ax,\n                    cbar_kws={'label': 'Valor Normalizado (0-1)'})\n        \n        ax.set_title('ğŸ”¥ Perfil de Cursos Top 10 (Normalizado)', \n                     fontsize=13, fontweight='bold')\n        ax.set_xlabel('MÃ©tricas', fontsize=11)\n        ax.set_ylabel('Curso', fontsize=11)\n        \n        plt.tight_layout()\n        plt.savefig(f'{fig_dir}viz_05_course_heatmap.png', dpi=150, bbox_inches='tight')\n        plt.show()\n        print(f\"âœ… Guardado: {fig_dir}viz_05_course_heatmap.png\")\nelse:\n    print(\"âš ï¸ No hay suficientes cursos para heatmap\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7. AnÃ¡lisis de Correlaciones entre MÃ©tricas"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 7.1 Matriz de correlaciÃ³n entre mÃ©tricas de curso\nif not courses_df.empty and len(courses_with_metrics) > 5:\n    # Seleccionar mÃ©tricas numÃ©ricas relevantes\n    corr_cols = ['total_students', 'n_students_with_grades', 'grade_std', 'grade_mean',\n                 'pass_rate', 'n_assignments', 'n_modules', 'n_quizzes',\n                 'avg_page_views', 'avg_participations', 'avg_on_time_rate', 'avg_missing_rate']\n    \n    available_corr_cols = [c for c in corr_cols if c in courses_with_metrics.columns]\n    \n    corr_data = courses_with_metrics[available_corr_cols].dropna(how='all', axis=1)\n    \n    if len(corr_data.columns) >= 4:\n        fig, ax = plt.subplots(figsize=(12, 10))\n        \n        corr_matrix = corr_data.corr()\n        \n        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n        \n        sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f',\n                    cmap='RdBu_r', center=0, vmin=-1, vmax=1,\n                    square=True, linewidths=1, ax=ax,\n                    cbar_kws={'label': 'CorrelaciÃ³n'})\n        \n        ax.set_title('ğŸ”— Matriz de CorrelaciÃ³n entre MÃ©tricas de Curso', \n                     fontsize=13, fontweight='bold')\n        \n        plt.tight_layout()\n        plt.savefig(f'{fig_dir}viz_06_correlation_matrix.png', dpi=150, bbox_inches='tight')\n        plt.show()\n        print(f\"âœ… Guardado: {fig_dir}viz_06_correlation_matrix.png\")\n        \n        # Mostrar correlaciones mÃ¡s fuertes\n        print(\"\\nğŸ“Š CORRELACIONES MÃS FUERTES (|r| > 0.5)\")\n        print(\"=\" * 50)\n        corr_pairs = []\n        cols = list(corr_matrix.columns)\n        for i in range(len(cols)):\n            for j in range(i+1, len(cols)):\n                r = corr_matrix.iloc[i, j]\n                if abs(r) > 0.5:\n                    corr_pairs.append({\n                        'Variables': f\"{cols[i]} â†” {cols[j]}\",\n                        'r': r\n                    })\n        \n        if corr_pairs:\n            corr_pairs_df = pd.DataFrame(corr_pairs)\n            corr_pairs_df = corr_pairs_df.sort_values('r', key=abs, ascending=False)\n            display(corr_pairs_df.round(3))\n        else:\n            print(\"No se encontraron correlaciones fuertes (|r| > 0.5)\")\nelse:\n    print(\"âš ï¸ No hay suficientes cursos para anÃ¡lisis de correlaciÃ³n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 7.2 AnÃ¡lisis: Â¿QuÃ© predice el Ã©xito estudiantil?\nif not courses_df.empty and 'pass_rate' in courses_with_metrics.columns:\n    # Correlaciones con pass_rate\n    numeric_cols = courses_with_metrics.select_dtypes(include=[np.number]).columns\n    \n    correlations_with_pass = {}\n    for col in numeric_cols:\n        if col != 'pass_rate':\n            valid_data = courses_with_metrics[[col, 'pass_rate']].dropna()\n            if len(valid_data) > 3:\n                r = valid_data[col].corr(valid_data['pass_rate'])\n                if not np.isnan(r):\n                    correlations_with_pass[col] = r\n    \n    if correlations_with_pass:\n        print(\"ğŸ“Š CORRELACIONES CON TASA DE APROBACIÃ“N\")\n        print(\"=\" * 50)\n        print(\"(Positivo = mÃ¡s de esta mÃ©trica â†’ mÃ¡s aprobaciÃ³n)\")\n        print()\n        \n        sorted_corr = sorted(correlations_with_pass.items(), key=lambda x: abs(x[1]), reverse=True)\n        \n        for var, r in sorted_corr[:10]:\n            direction = \"â†‘\" if r > 0 else \"â†“\"\n            strength = \"fuerte\" if abs(r) > 0.5 else \"moderada\" if abs(r) > 0.3 else \"dÃ©bil\"\n            print(f\"  {var}: r = {r:+.3f} ({direction} {strength})\")\nelse:\n    print(\"âš ï¸ No hay datos de pass_rate para anÃ¡lisis\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8. Ranking Final de Cursos para Early Warning"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Crear ranking final\nif not courses_df.empty and 'ew_potential_score' in courses_with_metrics.columns:\n    # Ordenar por score\n    ranked_courses = courses_with_metrics.sort_values('ew_potential_score', ascending=False).copy()\n    ranked_courses['rank'] = range(1, len(ranked_courses) + 1)\n    \n    print(\"ğŸ† RANKING FINAL DE CURSOS PARA EARLY WARNING\")\n    print(\"=\" * 70)\n    print(\"\\nCriterios de Ranking:\")\n    print(\"  â€¢ Grade Variance (30%): Mayor varianza = mejor predicciÃ³n\")\n    print(\"  â€¢ Pass Rate Score (20%): Ideal cerca de 50%\")\n    print(\"  â€¢ LMS Design (20%): MÃ¡s recursos = mÃ¡s seÃ±ales\")\n    print(\"  â€¢ Activity (15%): Engagement estudiantil\")\n    print(\"  â€¢ Data Quality (15%): Completitud de datos\")\n    print()\n    \n    # Tabla de ranking\n    ranking_cols = ['rank', 'course_id', 'course_name', 'total_students', \n                    'grade_std', 'pass_rate', 'n_assignments', 'ew_potential_score', 'recommendation']\n    available_cols = [c for c in ranking_cols if c in ranked_courses.columns]\n    \n    display(ranked_courses[available_cols].head(15).round(3))\n    \n    # EstadÃ­sticas\n    print(\"\\nğŸ“Š ESTADÃSTICAS DEL RANKING\")\n    print(\"=\" * 50)\n    print(f\"Total cursos analizados: {len(ranked_courses)}\")\n    print(f\"Cursos HIGH POTENTIAL: {(ranked_courses['recommendation'] == 'HIGH POTENTIAL').sum()}\")\n    print(f\"Cursos MEDIUM POTENTIAL: {(ranked_courses['recommendation'] == 'MEDIUM POTENTIAL').sum()}\")\n    print(f\"Promedio EW Score: {ranked_courses['ew_potential_score'].mean():.3f}\")\nelse:\n    print(\"âš ï¸ No hay datos para crear ranking\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# VisualizaciÃ³n del ranking final con breakdown de componentes\nif not courses_df.empty and 'ew_potential_score' in courses_with_metrics.columns:\n    fig, axes = plt.subplots(1, 2, figsize=(16, 10))\n    \n    # Top 15 para visualizaciÃ³n\n    top_15 = ranked_courses.head(15)\n    \n    if len(top_15) > 0:\n        # Plot 1: Ranking por EW Potential Score\n        ax1 = axes[0]\n        labels = [f\"#{row['rank']}: {row['course_name'][:30]}\" for _, row in top_15.iterrows()]\n        colors = plt.cm.RdYlGn(top_15['ew_potential_score'] / top_15['ew_potential_score'].max())\n        \n        bars = ax1.barh(range(len(top_15)), top_15['ew_potential_score'], color=colors)\n        ax1.set_yticks(range(len(top_15)))\n        ax1.set_yticklabels(labels, fontsize=9)\n        ax1.invert_yaxis()\n        ax1.set_xlabel('EW Potential Score', fontsize=11)\n        ax1.set_title('ğŸ† Top 15 Cursos - Ranking Final', fontsize=12, fontweight='bold')\n        \n        # Agregar valores\n        for bar, score in zip(bars, top_15['ew_potential_score']):\n            ax1.text(score + 0.005, bar.get_y() + bar.get_height()/2,\n                     f'{score:.3f}', va='center', fontsize=8)\n        \n        # Plot 2: Breakdown de componentes (stacked bar)\n        ax2 = axes[1]\n        \n        components = ['grade_variance_score', 'pass_rate_score', 'lms_design_score', \n                      'activity_score', 'data_quality_score']\n        component_labels = ['Grade Variance', 'Pass Rate', 'LMS Design', 'Activity', 'Data Quality']\n        component_colors = ['#e74c3c', '#3498db', '#2ecc71', '#f39c12', '#9b59b6']\n        \n        available_components = [c for c in components if c in top_15.columns]\n        \n        if available_components:\n            bottom = np.zeros(len(top_15))\n            for comp, label, color in zip(components, component_labels, component_colors):\n                if comp in top_15.columns:\n                    values = top_15[comp].fillna(0).values\n                    ax2.barh(range(len(top_15)), values, left=bottom, \n                             label=label, color=color, alpha=0.8)\n                    bottom += values\n            \n            ax2.set_yticks(range(len(top_15)))\n            ax2.set_yticklabels([f\"#{r}\" for r in top_15['rank']], fontsize=9)\n            ax2.invert_yaxis()\n            ax2.set_xlabel('Score Components', fontsize=11)\n            ax2.set_title('ğŸ“Š Desglose por Componente', fontsize=12, fontweight='bold')\n            ax2.legend(loc='lower right', fontsize=8)\n        \n        plt.tight_layout()\n        plt.savefig(f'{fig_dir}viz_07_final_ranking.png', dpi=150, bbox_inches='tight')\n        plt.show()\n        print(f\"âœ… Guardado: {fig_dir}viz_07_final_ranking.png\")\nelse:\n    print(\"âš ï¸ No hay datos para visualizar ranking\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9. Insights y Recomendaciones por Curso"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_course_insights(df):\n    \"\"\"\n    Genera insights automÃ¡ticos basados en los cursos analizados.\n    \"\"\"\n    insights = []\n    \n    if df.empty:\n        return [\"âš ï¸ No hay datos para generar insights\"]\n    \n    # Top performer\n    if 'ew_potential_score' in df.columns:\n        top = df.nlargest(1, 'ew_potential_score').iloc[0]\n        insights.append(f\"ğŸ¥‡ **Mejor curso para EW:** {top['course_name'][:40]} (score: {top['ew_potential_score']:.3f})\")\n    \n    # Curso con mayor varianza de notas\n    if 'grade_std' in df.columns:\n        high_var = df.nlargest(1, 'grade_std').iloc[0]\n        if pd.notna(high_var['grade_std']):\n            insights.append(f\"ğŸ“Š **Mayor varianza:** {high_var['course_name'][:40]} (Ïƒ={high_var['grade_std']:.1f})\")\n    \n    # Curso con mÃ¡s actividad\n    if 'avg_page_views' in df.columns:\n        high_activity = df.nlargest(1, 'avg_page_views').iloc[0]\n        insights.append(f\"ğŸš€ **MÃ¡s activo:** {high_activity['course_name'][:40]} ({high_activity['avg_page_views']:.0f} views/estudiante)\")\n    \n    # Curso con mejor pass rate en zona ideal\n    if 'pass_rate' in df.columns:\n        ideal_zone = df[(df['pass_rate'] >= 0.3) & (df['pass_rate'] <= 0.7)]\n        if len(ideal_zone) > 0:\n            best_ideal = ideal_zone.nlargest(1, 'ew_potential_score').iloc[0]\n            insights.append(f\"ğŸ¯ **Mejor en zona ideal:** {best_ideal['course_name'][:40]} (pass rate: {best_ideal['pass_rate']:.0%})\")\n    \n    # EstadÃ­sticas generales\n    if 'has_grades' in df.columns:\n        pct_with_grades = df['has_grades'].mean() * 100\n        insights.append(f\"ğŸ“ˆ **Cursos con notas:** {pct_with_grades:.0f}% ({df['has_grades'].sum()}/{len(df)})\")\n    \n    # Promedio de recursos\n    if 'n_assignments' in df.columns:\n        avg_assignments = df['n_assignments'].mean()\n        insights.append(f\"ğŸ“ **Promedio assignments:** {avg_assignments:.1f} por curso\")\n    \n    return insights\n\n\nif not courses_df.empty:\n    print(\"ğŸ’¡ INSIGHTS PRINCIPALES\")\n    print(\"=\" * 60)\n    \n    insights = generate_course_insights(courses_with_metrics)\n    for insight in insights:\n        print(f\"\\n{insight}\")\nelse:\n    print(\"âš ï¸ No hay datos para generar insights\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Recomendaciones especÃ­ficas por curso (Top 5)\ndef generate_course_recommendations(row):\n    \"\"\"\n    Genera recomendaciones especÃ­ficas para cada curso.\n    \"\"\"\n    recs = []\n    \n    # Baja varianza de notas\n    if pd.notna(row.get('grade_std')) and row['grade_std'] < 10:\n        recs.append(\"âš ï¸ Baja varianza de notas - difÃ­cil para predicciÃ³n\")\n    \n    # Pass rate extremo\n    if pd.notna(row.get('pass_rate')):\n        if row['pass_rate'] < 0.2:\n            recs.append(\"âŒ Pass rate muy bajo (<20%) - revisar dificultad\")\n        elif row['pass_rate'] > 0.9:\n            recs.append(\"âš ï¸ Pass rate muy alto (>90%) - poca seÃ±al de riesgo\")\n    \n    # Pocos assignments\n    if row.get('n_assignments', 0) < 5:\n        recs.append(\"ğŸ“ Pocos assignments - agregar mÃ¡s evaluaciones\")\n    \n    # Baja actividad\n    if pd.notna(row.get('avg_page_views')) and row['avg_page_views'] < 50:\n        recs.append(\"ğŸ“‰ Baja actividad estudiantil - revisar engagement\")\n    \n    # Alta tasa de missing\n    if pd.notna(row.get('avg_missing_rate')) and row['avg_missing_rate'] > 0.3:\n        recs.append(\"â° Alta tasa de entregas faltantes ({:.0%})\".format(row['avg_missing_rate']))\n    \n    if not recs:\n        recs.append(\"âœ… Buen candidato para Early Warning\")\n    \n    return recs\n\n\nif not courses_df.empty and 'ew_potential_score' in courses_with_metrics.columns:\n    print(\"ğŸ“‹ RECOMENDACIONES POR CURSO (Top 10)\")\n    print(\"=\" * 70)\n    \n    top_10 = courses_with_metrics.nlargest(10, 'ew_potential_score')\n    \n    for idx, (_, row) in enumerate(top_10.iterrows(), 1):\n        recs = generate_course_recommendations(row)\n        print(f\"\\n#{idx} {row['course_name'][:50]}\")\n        print(f\"    Course ID: {row['course_id']} | Score: {row['ew_potential_score']:.3f}\")\n        for rec in recs:\n            print(f\"    â†’ {rec}\")\nelse:\n    print(\"âš ï¸ No hay datos para recomendaciones\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10. Exportar Resultados"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Guardar resultados\noutput_dir = '../data/analytics/'\nos.makedirs(output_dir, exist_ok=True)\n\nif not courses_df.empty and 'ew_potential_score' in courses_with_metrics.columns:\n    # CSV con ranking completo\n    export_cols = ['rank', 'course_id', 'course_name', 'account_name', 'total_students',\n                   'n_students_with_grades', 'grade_mean', 'grade_std', 'pass_rate',\n                   'n_assignments', 'n_modules', 'n_quizzes',\n                   'avg_page_views', 'avg_participations',\n                   'ew_potential_score', 'recommendation']\n    available_export = [c for c in export_cols if c in ranked_courses.columns]\n    \n    ranked_courses[available_export].to_csv(f'{output_dir}course_ranking_results.csv', index=False)\n    print(f\"âœ… Guardado: {output_dir}course_ranking_results.csv\")\n    \n    # JSON con resumen\n    summary = {\n        'generated_at': datetime.now().isoformat(),\n        'term_id': ACTIVE_TERM_ID,\n        'accounts_scanned': list(ACCOUNTS_TO_SCAN.keys()),\n        'total_courses_analyzed': len(ranked_courses),\n        'courses_with_grades': int(ranked_courses['has_grades'].sum()),\n        'high_potential_courses': int((ranked_courses['recommendation'] == 'HIGH POTENTIAL').sum()),\n        'medium_potential_courses': int((ranked_courses['recommendation'] == 'MEDIUM POTENTIAL').sum()),\n        'top_5_courses': ranked_courses.head(5)[['course_id', 'course_name', 'ew_potential_score']].to_dict('records'),\n        'insights': insights if 'insights' in dir() else []\n    }\n    \n    with open(f'{output_dir}course_analytics_summary.json', 'w', encoding='utf-8') as f:\n        json.dump(summary, f, indent=2, ensure_ascii=False, default=str)\n    print(f\"âœ… Guardado: {output_dir}course_analytics_summary.json\")\n    \n    # Lista de cursos candidatos para Stage 2 (Page Views ETL)\n    candidates = ranked_courses[ranked_courses['recommendation'].str.contains('HIGH|MEDIUM', na=False)]\n    candidates_list = candidates[['course_id', 'course_name', 'total_students', 'ew_potential_score']].to_dict('records')\n    \n    with open(f'{output_dir}stage2_candidates.json', 'w', encoding='utf-8') as f:\n        json.dump(candidates_list, f, indent=2, ensure_ascii=False)\n    print(f\"âœ… Guardado: {output_dir}stage2_candidates.json ({len(candidates_list)} candidatos)\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"âœ… ANÃLISIS A NIVEL DE CURSO COMPLETADO\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## Resumen de MÃ©tricas Utilizadas (Nivel de Curso)\n\n### MÃ©tricas de Entrada (APIs de Canvas)\n\n| MÃ©trica | API | DescripciÃ³n |\n|---------|-----|-------------|\n| `n_students` | Enrollments | Estudiantes matriculados |\n| `final_score` | Enrollments | Nota final del estudiante |\n| `page_views` | Student Summaries | Vistas de pÃ¡gina por estudiante |\n| `participations` | Student Summaries | Participaciones por estudiante |\n| `tardiness_breakdown` | Student Summaries | on_time, late, missing |\n| `n_assignments` | Assignments | Cantidad de tareas/evaluaciones |\n| `n_modules` | Modules | Cantidad de mÃ³dulos |\n| `n_quizzes` | Quizzes | Cantidad de cuestionarios |\n\n### MÃ©tricas Calculadas\n\n| MÃ©trica | DescripciÃ³n | Peso en Ranking |\n|---------|-------------|-----------------|\n| `grade_std` | DesviaciÃ³n estÃ¡ndar de notas | 30% |\n| `pass_rate` | Tasa de aprobaciÃ³n (>=57%) | 20% |\n| `lms_design_score` | Score de diseÃ±o LMS | 20% |\n| `activity_score` | Score de actividad | 15% |\n| `data_quality_score` | Completitud de datos | 15% |\n| `ew_potential_score` | **Score final para Early Warning** | - |\n\n### Criterios de RecomendaciÃ³n\n\n| RecomendaciÃ³n | Criterios |\n|---------------|-----------|\n| HIGH POTENTIAL | grade_std > 10, 5+ assignments, pass_rate 20-80% |\n| MEDIUM POTENTIAL | grade_std > 10, 3+ assignments |\n| LOW | grade_std < 10 o pocos assignments |\n| SKIP | Sin datos de notas |\n\n---\n\n*Notebook modificado para anÃ¡lisis a nivel de CURSO*  \n*Proyecto Early Warning System - U. AutÃ³noma de Chile*  \n*Ãšltima actualizaciÃ³n: Diciembre 2025*"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}