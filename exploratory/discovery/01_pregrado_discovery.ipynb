{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGRADO Course Discovery\n",
    "\n",
    "**Objective:** Find high-potential courses for early failure prediction analysis in PREGRADO (excluding already-analyzed Control de Gestión Account 719).\n",
    "\n",
    "**Criteria for High-Potential Courses:**\n",
    "1. 20+ students (statistical significance)\n",
    "2. Grade variance > 10 (standard deviation of final_score)\n",
    "3. Pass rate 20-80% (class diversity for ML)\n",
    "4. 5+ assignments (good LMS design)\n",
    "5. Current or recent term (term_id 336 or 322)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & API Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.8.10)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/vicho1950/u_autonoma/venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "API_URL = os.getenv('CANVAS_API_URL')\n",
    "API_TOKEN = os.getenv('CANVAS_API_TOKEN')\n",
    "headers = {'Authorization': f'Bearer {API_TOKEN}'}\n",
    "\n",
    "# Configuration\n",
    "PREGRADO_ID = 46\n",
    "EXCLUDE_ACCOUNTS = [719]  # Already analyzed: Ing. en Control de Gestión\n",
    "TARGET_TERMS = [336, 322]  # 2nd Sem 2025 (current) and 1st Sem 2025 (recent past)\n",
    "MIN_STUDENTS = 15\n",
    "\n",
    "print(f\"API URL: {API_URL}\")\n",
    "print(f\"Token configured: {'Yes' if API_TOKEN else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test API connection\n",
    "r = requests.get(f'{API_URL}/api/v1/users/self', headers=headers)\n",
    "if r.status_code == 200:\n",
    "    user = r.json()\n",
    "    print(f\"Connected as: {user.get('name', 'Unknown')}\")\n",
    "    print(f\"User ID: {user.get('id')}\")\n",
    "    print(f\"Rate Limit Remaining: {r.headers.get('X-Rate-Limit-Remaining', 'N/A')}\")\n",
    "else:\n",
    "    print(f\"Connection failed: {r.status_code}\")\n",
    "    print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rate Limit Management\n",
    "\n",
    "Canvas API has rate limits. We'll implement adaptive delays based on remaining quota."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def calculate_delay(remaining_quota):\n    \"\"\"\n    Calculate delay based on remaining API quota.\n    More aggressive backing off as quota decreases.\n    \"\"\"\n    if remaining_quota < 50:\n        return 30  # Critical\n    elif remaining_quota < 100:\n        return 10  # Very low\n    elif remaining_quota < 200:\n        return 5   # Low\n    elif remaining_quota < 300:\n        return 2   # Moderate\n    elif remaining_quota < 500:\n        return 1   # Healthy\n    else:\n        return 0.5  # Abundant\n\ndef safe_request(url, headers, params=None, max_retries=3):\n    \"\"\"\n    Make a request with rate limit handling.\n    Returns (response_json, rate_limit_remaining) or (None, 0) on failure.\n    \"\"\"\n    for attempt in range(max_retries):\n        try:\n            r = requests.get(url, headers=headers, params=params, timeout=30)\n            remaining = int(float(r.headers.get('X-Rate-Limit-Remaining', 700)))\n            \n            if r.status_code == 403:\n                print(f\"Rate limited! Waiting 60s... (attempt {attempt + 1})\")\n                time.sleep(60)\n                continue\n            \n            if r.status_code == 200:\n                delay = calculate_delay(remaining)\n                time.sleep(delay)\n                return r.json(), remaining\n            else:\n                print(f\"Error {r.status_code}: {r.text[:100]}\")\n                return None, remaining\n                \n        except Exception as e:\n            print(f\"Request failed (attempt {attempt + 1}): {e}\")\n            time.sleep(2 ** attempt)\n    \n    return None, 0\n\nprint(\"Rate limit functions defined.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Discover PREGRADO Sub-Accounts\n",
    "\n",
    "Get all sub-accounts under PREGRADO (Account 46), excluding Control de Gestión (719)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PREGRADO sub-accounts\n",
    "sub_accounts_data, remaining = safe_request(\n",
    "    f'{API_URL}/api/v1/accounts/{PREGRADO_ID}/sub_accounts',\n",
    "    headers,\n",
    "    params={'per_page': 100}\n",
    ")\n",
    "\n",
    "if sub_accounts_data:\n",
    "    # Filter out already-analyzed accounts\n",
    "    sub_accounts = [a for a in sub_accounts_data if a['id'] not in EXCLUDE_ACCOUNTS]\n",
    "    \n",
    "    print(f\"Total PREGRADO sub-accounts: {len(sub_accounts_data)}\")\n",
    "    print(f\"Unexplored sub-accounts: {len(sub_accounts)}\")\n",
    "    print(f\"Rate limit remaining: {remaining}\")\n",
    "    print(\"\\nSub-accounts to explore:\")\n",
    "    for acc in sub_accounts[:10]:\n",
    "        print(f\"  {acc['id']}: {acc['name']}\")\n",
    "    if len(sub_accounts) > 10:\n",
    "        print(f\"  ... and {len(sub_accounts) - 10} more\")\n",
    "else:\n",
    "    print(\"Failed to fetch sub-accounts\")\n",
    "    sub_accounts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of sub-accounts for reference\n",
    "if sub_accounts:\n",
    "    sub_accounts_df = pd.DataFrame([\n",
    "        {'account_id': a['id'], 'name': a['name'], 'parent_id': a.get('parent_account_id')}\n",
    "        for a in sub_accounts\n",
    "    ])\n",
    "    display(sub_accounts_df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Scan Sub-Accounts for Courses\n",
    "\n",
    "We'll scan the top 3 sub-accounts (by size or priority) for courses with 15+ students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Target sub-accounts from pregrado_discovery_plan.md + Providencia expansion\n# These are the priority accounts to explore\nTARGET_SUB_ACCOUNTS = [\n    (730, \"Ingeniería Civil Industrial\"),\n    (247, \"Psicología\"),\n    (253, \"Derecho\"),\n    (176, \"Providencia\"),  # Added - large sede with 43 careers, 3393 courses\n]\n\n# If TARGET_SUB_ACCOUNTS is empty, use first 3 from discovered list\nif not TARGET_SUB_ACCOUNTS and sub_accounts:\n    TARGET_SUB_ACCOUNTS = [(a['id'], a['name']) for a in sub_accounts[:3]]\n\nprint(\"Target sub-accounts for course scanning:\")\nfor acc_id, name in TARGET_SUB_ACCOUNTS:\n    print(f\"  {acc_id}: {name}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_courses_from_account(account_id, term_ids=None, min_students=15):\n",
    "    \"\"\"\n",
    "    Get courses from an account with minimum student count.\n",
    "    Filters by enrollment term if specified.\n",
    "    \"\"\"\n",
    "    all_courses = []\n",
    "    \n",
    "    for term_id in (term_ids or [None]):\n",
    "        params = {\n",
    "            'per_page': 100,\n",
    "            'include[]': ['total_students', 'term'],\n",
    "            'with_enrollments': True\n",
    "        }\n",
    "        if term_id:\n",
    "            params['enrollment_term_id'] = term_id\n",
    "        \n",
    "        url = f'{API_URL}/api/v1/accounts/{account_id}/courses'\n",
    "        \n",
    "        while url:\n",
    "            data, remaining = safe_request(url, headers, params)\n",
    "            if not data:\n",
    "                break\n",
    "            \n",
    "            for course in data:\n",
    "                if course.get('total_students', 0) >= min_students:\n",
    "                    all_courses.append({\n",
    "                        'course_id': course['id'],\n",
    "                        'name': course['name'],\n",
    "                        'account_id': account_id,\n",
    "                        'students': course.get('total_students', 0),\n",
    "                        'term_name': course.get('term', {}).get('name', 'Unknown'),\n",
    "                        'term_id': course.get('enrollment_term_id')\n",
    "                    })\n",
    "            \n",
    "            # Check for pagination\n",
    "            # Canvas uses Link header for pagination\n",
    "            link_header = ''\n",
    "            if hasattr(data, 'headers'):\n",
    "                link_header = data.headers.get('Link', '')\n",
    "            url = None  # Simple version - just get first page\n",
    "            params = {}\n",
    "    \n",
    "    return all_courses\n",
    "\n",
    "print(\"Course fetching function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scan target sub-accounts for courses\n",
    "all_candidate_courses = []\n",
    "\n",
    "print(\"Scanning sub-accounts for courses...\\n\")\n",
    "\n",
    "for acc_id, acc_name in tqdm(TARGET_SUB_ACCOUNTS, desc=\"Sub-accounts\"):\n",
    "    print(f\"\\nScanning: {acc_name} (ID: {acc_id})\")\n",
    "    \n",
    "    courses = get_courses_from_account(acc_id, term_ids=TARGET_TERMS, min_students=MIN_STUDENTS)\n",
    "    \n",
    "    print(f\"  Found {len(courses)} courses with {MIN_STUDENTS}+ students\")\n",
    "    \n",
    "    all_candidate_courses.extend(courses)\n",
    "    \n",
    "    # Save progress\n",
    "    if courses:\n",
    "        for c in courses[:3]:\n",
    "            print(f\"    - {c['course_id']}: {c['name'][:40]}... ({c['students']} students)\")\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Total candidate courses: {len(all_candidate_courses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame of candidate courses\n",
    "if all_candidate_courses:\n",
    "    courses_df = pd.DataFrame(all_candidate_courses)\n",
    "    courses_df = courses_df.sort_values('students', ascending=False)\n",
    "    \n",
    "    print(f\"Candidate courses by student count:\")\n",
    "    display(courses_df.head(20))\n",
    "else:\n",
    "    print(\"No candidate courses found.\")\n",
    "    courses_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Course Potential\n",
    "\n",
    "For each candidate course, we'll check:\n",
    "- Grade availability and variance\n",
    "- Pass rate (57% threshold)\n",
    "- Number of assignments and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_course_potential(course_id):\n",
    "    \"\"\"\n",
    "    Analyze a course for analytical potential.\n",
    "    Returns dict with grades, variance, pass rate, and LMS design metrics.\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        'course_id': course_id,\n",
    "        'has_grades': False,\n",
    "        'n_students_with_grades': 0,\n",
    "        'grade_variance': 0.0,\n",
    "        'grade_mean': 0.0,\n",
    "        'pass_rate': None,\n",
    "        'n_assignments': 0,\n",
    "        'n_modules': 0,\n",
    "        'recommendation': 'SKIP'\n",
    "    }\n",
    "    \n",
    "    # 1. Get enrollments with grades\n",
    "    enrollments, _ = safe_request(\n",
    "        f'{API_URL}/api/v1/courses/{course_id}/enrollments',\n",
    "        headers,\n",
    "        params={\n",
    "            'type[]': 'StudentEnrollment',\n",
    "            'per_page': 100,\n",
    "            'include[]': 'grades'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    if enrollments:\n",
    "        grades = [\n",
    "            e['grades'].get('final_score')\n",
    "            for e in enrollments\n",
    "            if e.get('grades', {}).get('final_score') is not None\n",
    "        ]\n",
    "        \n",
    "        if len(grades) >= 10:\n",
    "            result['has_grades'] = True\n",
    "            result['n_students_with_grades'] = len(grades)\n",
    "            result['grade_variance'] = np.std(grades)\n",
    "            result['grade_mean'] = np.mean(grades)\n",
    "            result['pass_rate'] = sum(1 for g in grades if g >= 57) / len(grades)\n",
    "    \n",
    "    # 2. Count assignments\n",
    "    assignments, _ = safe_request(\n",
    "        f'{API_URL}/api/v1/courses/{course_id}/assignments',\n",
    "        headers,\n",
    "        params={'per_page': 100}\n",
    "    )\n",
    "    if assignments:\n",
    "        result['n_assignments'] = len(assignments)\n",
    "    \n",
    "    # 3. Count modules\n",
    "    modules, _ = safe_request(\n",
    "        f'{API_URL}/api/v1/courses/{course_id}/modules',\n",
    "        headers,\n",
    "        params={'per_page': 100}\n",
    "    )\n",
    "    if modules:\n",
    "        result['n_modules'] = len(modules)\n",
    "    \n",
    "    # 4. Determine recommendation\n",
    "    if result['has_grades'] and result['grade_variance'] > 10:\n",
    "        if result['n_assignments'] >= 5 and 0.2 <= (result['pass_rate'] or 0) <= 0.8:\n",
    "            result['recommendation'] = 'HIGH POTENTIAL'\n",
    "        elif result['n_assignments'] >= 3:\n",
    "            result['recommendation'] = 'MEDIUM POTENTIAL'\n",
    "        else:\n",
    "            result['recommendation'] = 'LOW - Few assignments'\n",
    "    elif result['has_grades']:\n",
    "        result['recommendation'] = 'LOW - Low grade variance'\n",
    "    else:\n",
    "        result['recommendation'] = 'SKIP - No grades'\n",
    "    \n",
    "    return result\n",
    "\n",
    "print(\"Course analysis function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all candidate courses\n",
    "# WARNING: This makes ~3 API calls per course. Be mindful of rate limits!\n",
    "\n",
    "analysis_results = []\n",
    "\n",
    "if len(courses_df) > 0:\n",
    "    print(f\"Analyzing {len(courses_df)} courses...\")\n",
    "    print(\"(This may take a while due to rate limiting)\\n\")\n",
    "    \n",
    "    for idx, row in tqdm(courses_df.iterrows(), total=len(courses_df), desc=\"Analyzing\"):\n",
    "        course_id = row['course_id']\n",
    "        \n",
    "        analysis = analyze_course_potential(course_id)\n",
    "        analysis['name'] = row['name']\n",
    "        analysis['account_id'] = row['account_id']\n",
    "        analysis['total_students'] = row['students']\n",
    "        analysis['term_id'] = row['term_id']\n",
    "        analysis['term_name'] = row['term_name']\n",
    "        \n",
    "        analysis_results.append(analysis)\n",
    "        \n",
    "        # Show progress for high-potential courses\n",
    "        if 'HIGH' in analysis['recommendation']:\n",
    "            print(f\"\\n  FOUND: {course_id} - {row['name'][:40]}\")\n",
    "            print(f\"    Variance: {analysis['grade_variance']:.1f}, Pass Rate: {analysis['pass_rate']:.0%}\")\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Analysis complete: {len(analysis_results)} courses analyzed\")\n",
    "else:\n",
    "    print(\"No courses to analyze.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results DataFrame\n",
    "if analysis_results:\n",
    "    results_df = pd.DataFrame(analysis_results)\n",
    "    \n",
    "    # Sort by recommendation and grade variance\n",
    "    results_df['rec_order'] = results_df['recommendation'].map({\n",
    "        'HIGH POTENTIAL': 1,\n",
    "        'MEDIUM POTENTIAL': 2,\n",
    "        'LOW - Few assignments': 3,\n",
    "        'LOW - Low grade variance': 4,\n",
    "        'SKIP - No grades': 5\n",
    "    })\n",
    "    results_df = results_df.sort_values(['rec_order', 'grade_variance'], ascending=[True, False])\n",
    "    \n",
    "    print(\"Top courses by potential:\")\n",
    "    display(results_df[[\n",
    "        'course_id', 'name', 'total_students', 'n_students_with_grades',\n",
    "        'grade_variance', 'pass_rate', 'n_assignments', 'recommendation'\n",
    "    ]].head(20))\n",
    "else:\n",
    "    results_df = pd.DataFrame()\n",
    "    print(\"No analysis results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Select Top 5 High-Potential Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to high and medium potential courses\n",
    "if len(results_df) > 0:\n",
    "    high_potential = results_df[results_df['recommendation'].str.contains('HIGH|MEDIUM')].copy()\n",
    "    \n",
    "    print(f\"High/Medium Potential Courses: {len(high_potential)}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for idx, row in high_potential.head(10).iterrows():\n",
    "        print(f\"\\n{row['recommendation']}\")\n",
    "        print(f\"  Course ID: {row['course_id']}\")\n",
    "        print(f\"  Name: {row['name']}\")\n",
    "        print(f\"  Students: {row['total_students']} (with grades: {row['n_students_with_grades']})\")\n",
    "        print(f\"  Grade Variance: {row['grade_variance']:.1f}\")\n",
    "        print(f\"  Pass Rate: {row['pass_rate']:.1%}\" if row['pass_rate'] else \"  Pass Rate: N/A\")\n",
    "        print(f\"  Assignments: {row['n_assignments']}, Modules: {row['n_modules']}\")\n",
    "        print(f\"  Term: {row['term_name']}\")\n",
    "else:\n",
    "    print(\"No results to display.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all results to CSV\n",
    "if len(results_df) > 0:\n",
    "    output_path = '../data/pregrado_discovery_results.csv'\n",
    "    \n",
    "    # Select and order columns for output\n",
    "    output_cols = [\n",
    "        'course_id', 'name', 'account_id', 'term_id', 'term_name',\n",
    "        'total_students', 'n_students_with_grades',\n",
    "        'grade_mean', 'grade_variance', 'pass_rate',\n",
    "        'n_assignments', 'n_modules', 'recommendation'\n",
    "    ]\n",
    "    \n",
    "    results_df[output_cols].to_csv(output_path, index=False)\n",
    "    print(f\"Results saved to: {output_path}\")\n",
    "    print(f\"Total courses: {len(results_df)}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nRecommendation Summary:\")\n",
    "    print(results_df['recommendation'].value_counts())\n",
    "else:\n",
    "    print(\"No results to save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary & Next Steps\n",
    "\n",
    "### Selected Top 5 Courses\n",
    "\n",
    "| Rank | Course ID | Name | Students | Grade Variance | Pass Rate | Assignments |\n",
    "|------|-----------|------|----------|----------------|-----------|-------------|\n",
    "| 1 | | | | | | |\n",
    "| 2 | | | | | | |\n",
    "| 3 | | | | | | |\n",
    "| 4 | | | | | | |\n",
    "| 5 | | | | | | |\n",
    "\n",
    "*(Fill in after running the analysis)*\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Review selected courses** - Verify they meet criteria\n",
    "2. **Extract page views** - Use `intern_exploration_guide.md` ETL code\n",
    "3. **Document findings** - Update project docs with new courses\n",
    "\n",
    "### Notes\n",
    "\n",
    "- Rate limit issues encountered: _(document here)_\n",
    "- Sub-accounts explored: _(list here)_\n",
    "- Date of analysis: _(add date)_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}