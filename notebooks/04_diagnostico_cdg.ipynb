{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnóstico Control de Gestión\n",
    "## Universidad Autónoma de Chile - Canvas LMS\n",
    "\n",
    "**Fecha:** Diciembre 2025  \n",
    "**Programa:** Ingeniería en Control de Gestión (Cuenta 719)  \n",
    "**Ambiente:** TEST (uautonoma.test.instructure.com)\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook genera el informe diagnóstico completo del programa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_URL = os.getenv('CANVAS_API_URL')\n",
    "API_TOKEN = os.getenv('CANVAS_API_TOKEN')\n",
    "headers = {'Authorization': f'Bearer {API_TOKEN}'}\n",
    "\n",
    "# Styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "# Data paths\n",
    "DATA_DIR = Path('../data')\n",
    "CORR_DIR = DATA_DIR / 'correlation_analysis'\n",
    "REPORT_DIR = DATA_DIR / 'report'\n",
    "\n",
    "print('Setup complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 1: Radiografía de Digitalización\n",
    "\n",
    "Análisis del diseño instruccional de los cursos en el LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Get all courses from Control de Gestión (Account 719)\n",
    "def get_account_courses(account_id):\n",
    "    \"\"\"Get all courses from an account.\"\"\"\n",
    "    courses = []\n",
    "    url = f'{API_URL}/api/v1/accounts/{account_id}/courses'\n",
    "    params = {'per_page': 100, 'include[]': ['total_students', 'term']}\n",
    "    \n",
    "    while url:\n",
    "        r = requests.get(url, headers=headers, params=params)\n",
    "        if r.status_code != 200:\n",
    "            break\n",
    "        courses.extend(r.json())\n",
    "        url = r.links.get('next', {}).get('url')\n",
    "        params = {}\n",
    "    \n",
    "    return courses\n",
    "\n",
    "cdg_courses = get_account_courses(719)\n",
    "print(f'Total cursos en Control de Gestión: {len(cdg_courses)}')\n",
    "\n",
    "# Filter courses with students\n",
    "active_courses = [c for c in cdg_courses if c.get('total_students', 0) > 0]\n",
    "print(f'Cursos con estudiantes activos: {len(active_courses)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Get resource counts for each active course\n",
    "import time\n",
    "\n",
    "def get_course_resources(course_id):\n",
    "    \"\"\"Count resources in a course.\"\"\"\n",
    "    resources = {'modules': 0, 'assignments': 0, 'quizzes': 0, 'pages': 0, 'files': 0, 'discussions': 0}\n",
    "    \n",
    "    endpoints = [\n",
    "        ('modules', 'modules'),\n",
    "        ('assignments', 'assignments'),\n",
    "        ('quizzes', 'quizzes'),\n",
    "        ('pages', 'pages'),\n",
    "        ('files', 'files'),\n",
    "        ('discussions', 'discussion_topics'),\n",
    "    ]\n",
    "    \n",
    "    for key, endpoint in endpoints:\n",
    "        r = requests.get(f'{API_URL}/api/v1/courses/{course_id}/{endpoint}', \n",
    "                        headers=headers, params={'per_page': 100})\n",
    "        if r.status_code == 200:\n",
    "            resources[key] = len(r.json())\n",
    "    \n",
    "    return resources\n",
    "\n",
    "# Extract resources for active courses\n",
    "course_resources = []\n",
    "for i, course in enumerate(active_courses[:35]):  # Limit to avoid rate limits\n",
    "    resources = get_course_resources(course['id'])\n",
    "    resources['course_id'] = course['id']\n",
    "    resources['name'] = course['name']\n",
    "    resources['students'] = course.get('total_students', 0)\n",
    "    resources['total_resources'] = sum(v for k, v in resources.items() if k not in ['course_id', 'name', 'students'])\n",
    "    course_resources.append(resources)\n",
    "    \n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f'Processed {i + 1} courses...')\n",
    "    time.sleep(0.3)\n",
    "\n",
    "df_resources = pd.DataFrame(course_resources)\n",
    "print(f'\\nExtracted resources for {len(df_resources)} courses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Classify courses by design quality\n",
    "def classify_design(row):\n",
    "    \"\"\"Classify course design as Excelente/Bueno/Básico.\"\"\"\n",
    "    score = 0\n",
    "    if row['modules'] >= 10: score += 3\n",
    "    elif row['modules'] >= 5: score += 2\n",
    "    elif row['modules'] >= 1: score += 1\n",
    "    \n",
    "    if row['assignments'] >= 15: score += 3\n",
    "    elif row['assignments'] >= 8: score += 2\n",
    "    elif row['assignments'] >= 3: score += 1\n",
    "    \n",
    "    if row['quizzes'] >= 10: score += 3\n",
    "    elif row['quizzes'] >= 5: score += 2\n",
    "    elif row['quizzes'] >= 1: score += 1\n",
    "    \n",
    "    if row['pages'] >= 5: score += 1\n",
    "    if row['discussions'] >= 3: score += 1\n",
    "    \n",
    "    if score >= 8:\n",
    "        return 'Excelente'\n",
    "    elif score >= 4:\n",
    "        return 'Bueno'\n",
    "    else:\n",
    "        return 'Básico'\n",
    "\n",
    "df_resources['design_quality'] = df_resources.apply(classify_design, axis=1)\n",
    "df_resources['design_score'] = df_resources.apply(\n",
    "    lambda r: 3 if r['design_quality'] == 'Excelente' else (2 if r['design_quality'] == 'Bueno' else 1), axis=1\n",
    ")\n",
    "\n",
    "# Summary\n",
    "design_summary = df_resources['design_quality'].value_counts()\n",
    "print('Distribución de Diseño Instruccional:')\n",
    "print(design_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Visualización: Heatmap de recursos por curso\n",
    "fig, ax = plt.subplots(figsize=(14, max(8, len(df_resources) * 0.3)))\n",
    "\n",
    "# Prepare data for heatmap\n",
    "resource_cols = ['modules', 'assignments', 'quizzes', 'pages', 'files', 'discussions']\n",
    "heatmap_data = df_resources.set_index('name')[resource_cols].head(25)  # Top 25 courses\n",
    "\n",
    "# Normalize for better visualization\n",
    "heatmap_norm = heatmap_data.apply(lambda x: (x - x.min()) / (x.max() - x.min() + 0.001))\n",
    "\n",
    "sns.heatmap(heatmap_norm, annot=heatmap_data.values, fmt='g', cmap='YlOrRd', \n",
    "            cbar_kws={'label': 'Normalizado'}, ax=ax)\n",
    "ax.set_title('Recursos por Curso - Control de Gestión', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Tipo de Recurso')\n",
    "ax.set_ylabel('Curso')\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORT_DIR / 'resource_heatmap.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Heatmap guardado en {REPORT_DIR}/resource_heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Top 10 cursos por diseño instruccional\n",
    "top_design = df_resources.nlargest(10, 'total_resources')[['name', 'students', 'modules', 'assignments', 'quizzes', 'design_quality']]\n",
    "print('Top 10 Cursos por Diseño Instruccional:')\n",
    "print(top_design.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 2: Análisis de Cursos con Notas\n",
    "\n",
    "Análisis de la distribución de notas y varianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Load correlation analysis data (pre-extracted)\n",
    "df_students = pd.read_csv(CORR_DIR / 'all_students_features.csv')\n",
    "\n",
    "print(f'Total estudiantes con features: {len(df_students)}')\n",
    "print(f'Cursos únicos: {df_students[\"course_id\"].nunique()}')\n",
    "print(f'\\nCursos:')\n",
    "print(df_students.groupby(['course_id', 'course_name'])['user_id'].count().reset_index().rename(columns={'user_id': 'n_students'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Grade statistics per course\n",
    "grade_stats = df_students.groupby('course_name').agg({\n",
    "    'final_score': ['count', 'mean', 'std', 'min', 'max'],\n",
    "    'failed': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "grade_stats.columns = ['N', 'Media', 'StdDev', 'Min', 'Max', 'Tasa_Reprobación']\n",
    "grade_stats['Tasa_Aprobación'] = (1 - grade_stats['Tasa_Reprobación']).round(2)\n",
    "grade_stats = grade_stats.sort_values('StdDev', ascending=False)\n",
    "\n",
    "print('Estadísticas de Notas por Curso:')\n",
    "print(grade_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Visualización: Boxplots de distribución de notas\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Create shorter names for display\n",
    "df_students['course_short'] = df_students['course_name'].apply(\n",
    "    lambda x: x[:30] + '...' if len(x) > 30 else x\n",
    ")\n",
    "\n",
    "order = df_students.groupby('course_short')['final_score'].median().sort_values(ascending=False).index\n",
    "\n",
    "sns.boxplot(data=df_students, x='course_short', y='final_score', order=order, palette='Set2', ax=ax)\n",
    "ax.axhline(y=57, color='red', linestyle='--', linewidth=2, label='Umbral Aprobación (57%)')\n",
    "ax.set_xlabel('Curso')\n",
    "ax.set_ylabel('Nota Final (%)')\n",
    "ax.set_title('Distribución de Notas por Curso - Control de Gestión', fontsize=14, fontweight='bold')\n",
    "ax.legend()\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORT_DIR / 'grade_boxplots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'Boxplots guardados en {REPORT_DIR}/grade_boxplots.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Histogramas por curso\n",
    "courses = df_students['course_name'].unique()\n",
    "n_courses = len(courses)\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, course in enumerate(courses[:6]):\n",
    "    data = df_students[df_students['course_name'] == course]['final_score']\n",
    "    ax = axes[i]\n",
    "    ax.hist(data, bins=15, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "    ax.axvline(x=57, color='red', linestyle='--', linewidth=2)\n",
    "    ax.axvline(x=data.mean(), color='green', linestyle='-', linewidth=2)\n",
    "    ax.set_title(course[:35], fontsize=10)\n",
    "    ax.set_xlabel('Nota (%)')\n",
    "    ax.set_ylabel('Frecuencia')\n",
    "\n",
    "# Hide extra subplots\n",
    "for i in range(n_courses, 6):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.suptitle('Histogramas de Notas por Curso', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORT_DIR / 'grade_histograms.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 3: Correlaciones Actividad-Rendimiento\n",
    "\n",
    "Análisis de cómo la actividad en el LMS predice las notas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Load pre-computed correlations\n",
    "with open(CORR_DIR / 'correlations_by_course.json', 'r') as f:\n",
    "    correlations_by_course = json.load(f)\n",
    "\n",
    "with open(CORR_DIR / 'average_correlations.json', 'r') as f:\n",
    "    avg_correlations = json.load(f)\n",
    "\n",
    "print('Correlaciones promedio (features de actividad pura):')\n",
    "print('-' * 60)\n",
    "for feat, data in sorted(avg_correlations.items(), key=lambda x: abs(x[1]['mean']), reverse=True):\n",
    "    print(f\"{feat:25s}: r = {data['mean']:+.3f} (std={data['std']:.3f}, {data['consistency']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Display existing correlation heatmaps\n",
    "from IPython.display import Image, display\n",
    "\n",
    "heatmap_path = CORR_DIR / 'correlation_heatmaps.png'\n",
    "if heatmap_path.exists():\n",
    "    print('Heatmaps de correlación por curso:')\n",
    "    display(Image(filename=str(heatmap_path), width=900))\n",
    "else:\n",
    "    print(f'Heatmap no encontrado en {heatmap_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Cross-course correlation summary heatmap\n",
    "summary_heatmap_path = CORR_DIR / 'correlation_summary_heatmap.png'\n",
    "if summary_heatmap_path.exists():\n",
    "    print('Resumen de correlaciones cross-curso:')\n",
    "    display(Image(filename=str(summary_heatmap_path), width=700))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Scatter plots: Top predictores vs nota\n",
    "top_features = ['unique_active_hours', 'total_activity_time', 'avg_gap_hours', 'gap_std_hours']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(top_features):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    for course in df_students['course_name'].unique():\n",
    "        course_data = df_students[df_students['course_name'] == course]\n",
    "        ax.scatter(course_data[feat], course_data['final_score'], alpha=0.6, label=course[:20])\n",
    "    \n",
    "    # Add trend line\n",
    "    x = df_students[feat].dropna()\n",
    "    y = df_students.loc[x.index, 'final_score']\n",
    "    z = np.polyfit(x, y, 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax.plot(sorted(x), p(sorted(x)), 'r--', linewidth=2, label='Tendencia')\n",
    "    \n",
    "    corr = avg_correlations.get(feat, {}).get('mean', 0)\n",
    "    ax.set_title(f'{feat}\\nr = {corr:+.2f}', fontsize=11)\n",
    "    ax.set_xlabel(feat)\n",
    "    ax.set_ylabel('Nota Final (%)')\n",
    "    ax.axhline(y=57, color='red', linestyle=':', alpha=0.5)\n",
    "\n",
    "# Add legend to first plot\n",
    "axes[0].legend(loc='upper left', fontsize=8)\n",
    "\n",
    "plt.suptitle('Top 4 Predictores de Actividad vs Nota Final', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORT_DIR / 'top_predictors_scatter.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# PARTE 4: Sistema de Alerta Temprana\n",
    "\n",
    "Propuesta de umbrales e indicadores de riesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Calculate risk score for each student\n",
    "def normalize(series):\n",
    "    \"\"\"Min-max normalization.\"\"\"\n",
    "    return (series - series.min()) / (series.max() - series.min() + 0.001)\n",
    "\n",
    "# Risk score formula (based on correlations)\n",
    "df_students['risk_score'] = (\n",
    "    - 0.36 * normalize(df_students['unique_active_hours'])\n",
    "    - 0.36 * normalize(df_students['total_activity_time'])\n",
    "    + 0.35 * normalize(df_students['avg_gap_hours'])\n",
    "    + 0.29 * normalize(df_students['gap_std_hours'])\n",
    ")\n",
    "\n",
    "# Normalize risk score to 0-100\n",
    "df_students['risk_score'] = normalize(df_students['risk_score']) * 100\n",
    "\n",
    "print('Risk Score calculado para cada estudiante')\n",
    "print(df_students[['course_name', 'user_id', 'final_score', 'failed', 'risk_score']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Validate risk score\n",
    "# Correlation between risk score and failure\n",
    "corr_risk_grade = df_students['risk_score'].corr(df_students['final_score'])\n",
    "corr_risk_fail = df_students['risk_score'].corr(df_students['failed'])\n",
    "\n",
    "print(f'Correlación Risk Score vs Nota Final: r = {corr_risk_grade:.3f}')\n",
    "print(f'Correlación Risk Score vs Reprobación: r = {corr_risk_fail:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Risk score distribution by outcome\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Histogram by outcome\n",
    "ax = axes[0]\n",
    "df_students[df_students['failed'] == 0]['risk_score'].hist(bins=20, alpha=0.7, label='Aprobados', ax=ax, color='green')\n",
    "df_students[df_students['failed'] == 1]['risk_score'].hist(bins=20, alpha=0.7, label='Reprobados', ax=ax, color='red')\n",
    "ax.set_xlabel('Risk Score')\n",
    "ax.set_ylabel('Frecuencia')\n",
    "ax.set_title('Distribución de Risk Score por Resultado')\n",
    "ax.legend()\n",
    "\n",
    "# Boxplot by outcome\n",
    "ax = axes[1]\n",
    "df_students.boxplot(column='risk_score', by='failed', ax=ax)\n",
    "ax.set_xlabel('Reprobado (0=No, 1=Sí)')\n",
    "ax.set_ylabel('Risk Score')\n",
    "ax.set_title('Risk Score por Resultado Académico')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(REPORT_DIR / 'risk_score_distribution.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Threshold analysis\n",
    "thresholds = [25, 50, 75]\n",
    "\n",
    "print('Análisis de Umbrales de Riesgo:')\n",
    "print('-' * 60)\n",
    "\n",
    "for threshold in thresholds:\n",
    "    high_risk = df_students['risk_score'] >= threshold\n",
    "    \n",
    "    # Students flagged\n",
    "    n_flagged = high_risk.sum()\n",
    "    pct_flagged = n_flagged / len(df_students) * 100\n",
    "    \n",
    "    # True positives (flagged and actually failed)\n",
    "    true_positives = ((high_risk) & (df_students['failed'] == 1)).sum()\n",
    "    actual_failures = df_students['failed'].sum()\n",
    "    \n",
    "    # Catch rate (recall)\n",
    "    catch_rate = true_positives / actual_failures * 100 if actual_failures > 0 else 0\n",
    "    \n",
    "    # Precision\n",
    "    precision = true_positives / n_flagged * 100 if n_flagged > 0 else 0\n",
    "    \n",
    "    print(f'Umbral {threshold}:')\n",
    "    print(f'  Estudiantes alertados: {n_flagged} ({pct_flagged:.1f}%)')\n",
    "    print(f'  Tasa de captura (recall): {catch_rate:.1f}%')\n",
    "    print(f'  Precisión: {precision:.1f}%')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 Feature thresholds (based on quartiles)\n",
    "print('Umbrales Propuestos para Indicadores de Alerta:')\n",
    "print('=' * 60)\n",
    "\n",
    "key_features = [\n",
    "    ('unique_active_hours', 'Horas únicas de actividad', 'bajo', 25),\n",
    "    ('total_activity_time', 'Tiempo total de actividad (seg)', 'bajo', 25),\n",
    "    ('avg_gap_hours', 'Brecha promedio entre sesiones (hrs)', 'alto', 75),\n",
    "    ('gap_std_hours', 'Variabilidad de brechas (hrs)', 'alto', 75),\n",
    "]\n",
    "\n",
    "for feat, name, risk_type, percentile in key_features:\n",
    "    threshold = df_students[feat].quantile(percentile / 100)\n",
    "    if risk_type == 'bajo':\n",
    "        at_risk = df_students[feat] < threshold\n",
    "    else:\n",
    "        at_risk = df_students[feat] > threshold\n",
    "    \n",
    "    fail_rate_at_risk = df_students[at_risk]['failed'].mean() * 100\n",
    "    fail_rate_normal = df_students[~at_risk]['failed'].mean() * 100\n",
    "    \n",
    "    print(f'\\n{name}:')\n",
    "    print(f'  Umbral: {risk_type} que {threshold:.1f}')\n",
    "    print(f'  Tasa de reprobación si en riesgo: {fail_rate_at_risk:.1f}%')\n",
    "    print(f'  Tasa de reprobación si normal: {fail_rate_normal:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Generación del Informe Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate markdown report\n",
    "report_content = f'''# Diagnóstico: Ingeniería en Control de Gestión\n",
    "## Universidad Autónoma de Chile - Canvas LMS\n",
    "\n",
    "**Fecha:** Diciembre 2025  \n",
    "**Programa:** Ingeniería en Control de Gestión (Cuenta 719)  \n",
    "**Ambiente:** TEST (uautonoma.test.instructure.com)\n",
    "\n",
    "---\n",
    "\n",
    "## Resumen Ejecutivo\n",
    "\n",
    "| Métrica | Valor |\n",
    "|---------|-------|\n",
    "| Cursos totales | {len(cdg_courses)} |\n",
    "| Cursos con estudiantes | {len(active_courses)} |\n",
    "| Cursos con notas válidas | {df_students['course_id'].nunique()} |\n",
    "| Estudiantes analizados | {len(df_students)} |\n",
    "| Tasa de reprobación promedio | {df_students['failed'].mean()*100:.1f}% |\n",
    "\n",
    "### Hallazgo Principal\n",
    "\n",
    "**La actividad en el LMS predice el rendimiento académico.**\n",
    "\n",
    "Los 4 indicadores más predictivos son:\n",
    "\n",
    "| Indicador | Correlación | Interpretación |\n",
    "|-----------|-------------|----------------|\n",
    "| Horas únicas de actividad | r = +0.36 | Más diversidad = mejor |\n",
    "| Tiempo total de actividad | r = +0.36 | Más tiempo = mejor |\n",
    "| Brecha promedio entre sesiones | r = -0.35 | Brechas largas = peor |\n",
    "| Variabilidad de brechas | r = -0.29 | Irregularidad = riesgo |\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 1: Radiografía de Digitalización\n",
    "\n",
    "### Distribución por Calidad de Diseño\n",
    "\n",
    "| Categoría | Cursos | Características |\n",
    "|-----------|--------|----------------|\n",
    "| Excelente | {design_summary.get('Excelente', 0)} | >10 módulos, >15 tareas, quizzes |\n",
    "| Bueno | {design_summary.get('Bueno', 0)} | 5-10 módulos, 8-15 tareas |\n",
    "| Básico | {design_summary.get('Básico', 0)} | <5 módulos, pocas actividades |\n",
    "\n",
    "### Top 5 Cursos por Diseño Instruccional\n",
    "\n",
    "| Curso | Módulos | Tareas | Quizzes | Estudiantes |\n",
    "|-------|---------|--------|---------|-------------|\n",
    "'''  \n",
    "\n",
    "for _, row in df_resources.nlargest(5, 'total_resources').iterrows():\n",
    "    report_content += f\"| {row['name'][:40]} | {row['modules']} | {row['assignments']} | {row['quizzes']} | {row['students']} |\\n\"\n",
    "\n",
    "report_content += f'''\n",
    "---\n",
    "\n",
    "## Parte 2: Análisis de Cursos con Notas\n",
    "\n",
    "### Cursos Analizados\n",
    "\n",
    "| Curso | N | Media | StdDev | Tasa Aprob |\n",
    "|-------|---|-------|--------|------------|\n",
    "'''\n",
    "\n",
    "for course, row in grade_stats.iterrows():\n",
    "    report_content += f\"| {course[:35]} | {int(row['N'])} | {row['Media']:.1f}% | {row['StdDev']:.1f} | {row['Tasa_Aprobación']*100:.0f}% |\\n\"\n",
    "\n",
    "report_content += f'''\n",
    "### Observaciones\n",
    "\n",
    "1. **FUND BUSINESS ANALYTICS-P01** tiene la mayor varianza (StdDev = 24.6) y menor tasa de aprobación (31%)\n",
    "2. **FUND MACROECONOMÍA-P03** muestra varianza significativa (StdDev = 21.4) útil para predicción\n",
    "3. **FUND MICROECONOMÍA-P01** tiene poca varianza (StdDev = 13.6) - menos útil para predicción\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 3: Correlaciones Actividad-Rendimiento\n",
    "\n",
    "### Features de Actividad Pura (sin data leakage)\n",
    "\n",
    "| Feature | Corr. Promedio | Consistencia | Accionable |\n",
    "|---------|----------------|--------------|------------|\n",
    "| unique_active_hours | +0.36 | Consistente | Monitorear diversidad |\n",
    "| total_activity_time | +0.36 | Consistente | Rastrear tiempo total |\n",
    "| avg_gap_hours | -0.35 | Consistente | Alertar brechas largas |\n",
    "| gap_std_hours | -0.29 | Mixto | Detectar irregularidad |\n",
    "| afternoon_activity | +0.22 | Mixto | - |\n",
    "| page_views | +0.21 | Mixto | Métrica básica |\n",
    "\n",
    "### Validación Externa (Pregrado)\n",
    "\n",
    "Se validó el modelo en 3 cursos de otras carreras:\n",
    "\n",
    "| Curso | Carrera | Validación |\n",
    "|-------|---------|------------|\n",
    "| ÁLGEBRA-P01 | Ing. Civil Industrial | ✓ Confirma patrones (r hasta +0.55) |\n",
    "| NEUROCIENCIAS-P01 | Medicina | ✗ Correlaciones débiles |\n",
    "| SALUD FAM.-P01 | Kinesiología | ✗ Patrones diferentes |\n",
    "\n",
    "**Conclusión:** Los indicadores funcionan mejor en programas de ingeniería/negocios.\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 4: Sistema de Alerta Temprana\n",
    "\n",
    "### Fórmula de Risk Score\n",
    "\n",
    "```\n",
    "risk_score = \n",
    "  - 0.36 × normalize(unique_active_hours)\n",
    "  - 0.36 × normalize(total_activity_time)\n",
    "  + 0.35 × normalize(avg_gap_hours)\n",
    "  + 0.29 × normalize(gap_std_hours)\n",
    "```\n",
    "\n",
    "### Validación del Risk Score\n",
    "\n",
    "- Correlación con nota final: r = {corr_risk_grade:.2f}\n",
    "- Correlación con reprobación: r = {corr_risk_fail:.2f}\n",
    "\n",
    "### Umbrales Recomendados\n",
    "\n",
    "| Indicador | Umbral de Alerta | Tasa Reprob. si Riesgo |\n",
    "|-----------|------------------|------------------------|\n",
    "| Horas únicas < Q1 | <{df_students['unique_active_hours'].quantile(0.25):.0f} horas | ~60% |\n",
    "| Tiempo total < Q1 | <{df_students['total_activity_time'].quantile(0.25):.0f} seg | ~55% |\n",
    "| Brecha promedio > Q3 | >{df_students['avg_gap_hours'].quantile(0.75):.0f} hrs | ~50% |\n",
    "\n",
    "---\n",
    "\n",
    "## Recomendaciones\n",
    "\n",
    "### Corto Plazo (1-2 semanas)\n",
    "1. Implementar alertas cuando brecha de actividad > 72 horas\n",
    "2. Monitorear estudiantes con < 10 horas únicas de actividad\n",
    "3. Priorizar cursos con diseño \"Básico\" para mejora\n",
    "\n",
    "### Mediano Plazo (1 mes)\n",
    "1. Dashboard de riesgo por curso y estudiante\n",
    "2. Intervención piloto en FUND BUSINESS ANALYTICS-P01\n",
    "3. Capacitar docentes en interpretación de métricas\n",
    "\n",
    "### Largo Plazo (1 semestre)\n",
    "1. Integrar sistema de alerta con tutoría académica\n",
    "2. Expandir análisis a más carreras de Pregrado\n",
    "3. Obtener notas de \"Libro de Calificaciones\" para cursos sin datos\n",
    "\n",
    "---\n",
    "\n",
    "## Anexo: Archivos Generados\n",
    "\n",
    "| Archivo | Descripción |\n",
    "|---------|-------------|\n",
    "| `resource_heatmap.png` | Mapa de recursos por curso |\n",
    "| `grade_boxplots.png` | Distribución de notas |\n",
    "| `grade_histograms.png` | Histogramas por curso |\n",
    "| `top_predictors_scatter.png` | Scatter de predictores |\n",
    "| `risk_score_distribution.png` | Distribución de riesgo |\n",
    "\n",
    "---\n",
    "\n",
    "*Informe generado automáticamente - Diciembre 2025*\n",
    "'''\n",
    "\n",
    "# Save report\n",
    "report_path = REPORT_DIR / 'DIAGNOSTICO_CONTROL_GESTION.md'\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(report_content)\n",
    "\n",
    "print(f'Informe guardado en: {report_path}')\n",
    "print(f'Longitud: {len(report_content)} caracteres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print('=' * 60)\n",
    "print('DIAGNÓSTICO COMPLETO')\n",
    "print('=' * 60)\n",
    "print(f'''\\n\n",
    "Archivos generados:\n",
    "  - {REPORT_DIR}/DIAGNOSTICO_CONTROL_GESTION.md\n",
    "  - {REPORT_DIR}/resource_heatmap.png\n",
    "  - {REPORT_DIR}/grade_boxplots.png\n",
    "  - {REPORT_DIR}/grade_histograms.png\n",
    "  - {REPORT_DIR}/top_predictors_scatter.png\n",
    "  - {REPORT_DIR}/risk_score_distribution.png\n",
    "\n",
    "Hallazgos clave:\n",
    "  1. {len(active_courses)} cursos activos, {design_summary.get('Excelente', 0) + design_summary.get('Bueno', 0)} con buen diseño\n",
    "  2. {len(df_students)} estudiantes analizados, {df_students['failed'].mean()*100:.1f}% reprobados\n",
    "  3. Top predictores: unique_active_hours, total_activity_time, avg_gap_hours\n",
    "  4. Risk score correlaciona {corr_risk_fail:.2f} con reprobación\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
